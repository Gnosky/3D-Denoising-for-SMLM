Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W1202 21:08:57.473717 140461547808576 deprecation_wrapper.py:119] From train.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W1202 21:08:57.473995 140461547808576 deprecation_wrapper.py:119] From train.py:29: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-12-02 21:08:57.489653: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-12-02 21:08:57.499083: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-12-02 21:08:57.838837: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ba2fb0 executing computations on platform CUDA. Devices:
2019-12-02 21:08:57.838922: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2019-12-02 21:08:57.841851: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1995940000 Hz
2019-12-02 21:08:57.845274: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x61b18a0 executing computations on platform Host. Devices:
2019-12-02 21:08:57.845304: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-02 21:08:57.848040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:42:00.0
2019-12-02 21:08:57.848401: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-12-02 21:08:57.849919: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-12-02 21:08:57.851452: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-12-02 21:08:57.851757: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-12-02 21:08:57.853596: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-12-02 21:08:57.854960: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-12-02 21:08:57.858568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-12-02 21:08:57.863525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-12-02 21:08:57.863578: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-12-02 21:08:57.866470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-12-02 21:08:57.866490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-12-02 21:08:57.866503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-12-02 21:08:57.871653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30265 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:42:00.0, compute capability: 7.0)
W1202 21:09:00.593864 140461547808576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

W1202 21:09:00.594337 140461547808576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W1202 21:09:00.605085 140461547808576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W1202 21:09:02.641227 140461547808576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

W1202 21:09:02.703646 140461547808576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2019-12-02 21:09:07.989841: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-12-02 21:09:11.343660: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
1.8623832 0.63019526
Epoch 1/1000

1/2 [==============>...............] - ETA: 11s - loss: 0.71502019-12-02 21:09:17.522076: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-12-02 21:09:17.523838: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-12-02 21:09:17.525774: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] layout failed: Invalid argument: The graph couldn't be sorted in topological order.
2019-12-02 21:09:17.536975: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] remapper failed: Invalid argument: The graph couldn't be sorted in topological order.
2019-12-02 21:09:17.537982: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] arithmetic_optimizer failed: Invalid argument: The graph couldn't be sorted in topological order.
2019-12-02 21:09:17.538980: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-12-02 21:09:17.540578: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.

2/2 [==============================] - 14s 7s/step - loss: 30.5641 - val_loss: 0.4867

Epoch 00001: val_loss improved from inf to 0.48668, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 2/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.3520
2/2 [==============================] - 2s 1s/step - loss: 0.4229 - val_loss: 0.2894

Epoch 00002: val_loss improved from 0.48668 to 0.28943, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 3/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.2423
2/2 [==============================] - 2s 1s/step - loss: 0.2192 - val_loss: 0.2640

Epoch 00003: val_loss improved from 0.28943 to 0.26404, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 4/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.2684
2/2 [==============================] - 2s 1s/step - loss: 0.2734 - val_loss: 0.2535

Epoch 00004: val_loss improved from 0.26404 to 0.25351, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 5/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.2836
2/2 [==============================] - 2s 1s/step - loss: 0.2236 - val_loss: 0.2262

Epoch 00005: val_loss improved from 0.25351 to 0.22619, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 6/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.2332
2/2 [==============================] - 2s 1s/step - loss: 0.2077 - val_loss: 0.1692

Epoch 00006: val_loss improved from 0.22619 to 0.16919, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 7/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.2111
2/2 [==============================] - 2s 1s/step - loss: 0.3084 - val_loss: 0.1754

Epoch 00007: val_loss did not improve from 0.16919
Epoch 8/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.1785
2/2 [==============================] - 2s 1s/step - loss: 0.1847 - val_loss: 0.1244

Epoch 00008: val_loss improved from 0.16919 to 0.12444, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 9/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.1341
2/2 [==============================] - 2s 1s/step - loss: 0.1431 - val_loss: 0.1515

Epoch 00009: val_loss did not improve from 0.12444
Epoch 10/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.1732
2/2 [==============================] - 2s 1s/step - loss: 0.1531 - val_loss: 0.1339

Epoch 00010: val_loss did not improve from 0.12444
Epoch 11/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.1250
2/2 [==============================] - 2s 1s/step - loss: 0.1088 - val_loss: 0.1294

Epoch 00011: val_loss did not improve from 0.12444
Epoch 12/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.1125
2/2 [==============================] - 2s 1s/step - loss: 0.1040 - val_loss: 0.0949

Epoch 00012: val_loss improved from 0.12444 to 0.09491, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 13/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.1106
2/2 [==============================] - 2s 1s/step - loss: 0.1009 - val_loss: 0.0791

Epoch 00013: val_loss improved from 0.09491 to 0.07906, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 14/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0924
2/2 [==============================] - 2s 1s/step - loss: 0.0939 - val_loss: 0.0761

Epoch 00014: val_loss improved from 0.07906 to 0.07611, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 15/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0828
2/2 [==============================] - 2s 1s/step - loss: 0.0906 - val_loss: 0.0598

Epoch 00015: val_loss improved from 0.07611 to 0.05981, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 16/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0945
2/2 [==============================] - 2s 1s/step - loss: 0.0886 - val_loss: 0.0717

Epoch 00016: val_loss did not improve from 0.05981
Epoch 17/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0708
2/2 [==============================] - 2s 1s/step - loss: 0.0775 - val_loss: 0.0738

Epoch 00017: val_loss did not improve from 0.05981
Epoch 18/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0951
2/2 [==============================] - 2s 1s/step - loss: 0.0913 - val_loss: 0.0647

Epoch 00018: val_loss did not improve from 0.05981
Epoch 19/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0596
2/2 [==============================] - 2s 1s/step - loss: 0.0657 - val_loss: 0.0647

Epoch 00019: val_loss did not improve from 0.05981
Epoch 20/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0719
2/2 [==============================] - 2s 1s/step - loss: 0.0721 - val_loss: 0.0653

Epoch 00020: val_loss did not improve from 0.05981
Epoch 21/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0686
2/2 [==============================] - 2s 1s/step - loss: 0.0672 - val_loss: 0.0606

Epoch 00021: val_loss did not improve from 0.05981
Epoch 22/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0530
2/2 [==============================] - 2s 1s/step - loss: 0.0508 - val_loss: 0.0422

Epoch 00022: val_loss improved from 0.05981 to 0.04223, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 23/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0634
2/2 [==============================] - 2s 1s/step - loss: 0.0630 - val_loss: 0.0543

Epoch 00023: val_loss did not improve from 0.04223
Epoch 24/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0575
2/2 [==============================] - 2s 1s/step - loss: 0.0609 - val_loss: 0.0580

Epoch 00024: val_loss did not improve from 0.04223
Epoch 25/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0618
2/2 [==============================] - 2s 1s/step - loss: 0.0610 - val_loss: 0.0539

Epoch 00025: val_loss did not improve from 0.04223
Epoch 26/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0523
2/2 [==============================] - 2s 1s/step - loss: 0.0465 - val_loss: 0.0481

Epoch 00026: val_loss did not improve from 0.04223
Epoch 27/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0474
2/2 [==============================] - 2s 1s/step - loss: 0.0519 - val_loss: 0.0517

Epoch 00027: val_loss did not improve from 0.04223
Epoch 28/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0431
2/2 [==============================] - 2s 1s/step - loss: 0.0522 - val_loss: 0.0528

Epoch 00028: val_loss did not improve from 0.04223
Epoch 29/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0584
2/2 [==============================] - 2s 1s/step - loss: 0.0512 - val_loss: 0.0407

Epoch 00029: val_loss improved from 0.04223 to 0.04071, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 30/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0530
2/2 [==============================] - 2s 1s/step - loss: 0.0508 - val_loss: 0.0566

Epoch 00030: val_loss did not improve from 0.04071
Epoch 31/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0404
2/2 [==============================] - 2s 1s/step - loss: 0.0456 - val_loss: 0.0459

Epoch 00031: val_loss did not improve from 0.04071
Epoch 32/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0464
2/2 [==============================] - 2s 1s/step - loss: 0.0482 - val_loss: 0.0347

Epoch 00032: val_loss improved from 0.04071 to 0.03465, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 33/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0448
2/2 [==============================] - 2s 1s/step - loss: 0.0452 - val_loss: 0.0430

Epoch 00033: val_loss did not improve from 0.03465
Epoch 34/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0482
2/2 [==============================] - 2s 1s/step - loss: 0.0467 - val_loss: 0.0398

Epoch 00034: val_loss did not improve from 0.03465
Epoch 35/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0449
2/2 [==============================] - 2s 1s/step - loss: 0.0446 - val_loss: 0.0401

Epoch 00035: val_loss did not improve from 0.03465
Epoch 36/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0476
2/2 [==============================] - 2s 1s/step - loss: 0.0428 - val_loss: 0.0420

Epoch 00036: val_loss did not improve from 0.03465
Epoch 37/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0331
2/2 [==============================] - 2s 1s/step - loss: 0.0372 - val_loss: 0.0415

Epoch 00037: val_loss did not improve from 0.03465
Epoch 38/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0392
2/2 [==============================] - 2s 1s/step - loss: 0.0468 - val_loss: 0.0377

Epoch 00038: val_loss did not improve from 0.03465
Epoch 39/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0383
2/2 [==============================] - 2s 1s/step - loss: 0.0355 - val_loss: 0.0371

Epoch 00039: val_loss did not improve from 0.03465
Epoch 40/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0325
2/2 [==============================] - 2s 1s/step - loss: 0.0372 - val_loss: 0.0409

Epoch 00040: val_loss did not improve from 0.03465
Epoch 41/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0381
2/2 [==============================] - 2s 1s/step - loss: 0.0393 - val_loss: 0.0427

Epoch 00041: val_loss did not improve from 0.03465
Epoch 42/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0407
2/2 [==============================] - 2s 1s/step - loss: 0.0419 - val_loss: 0.0485

Epoch 00042: val_loss did not improve from 0.03465
Epoch 43/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0428
2/2 [==============================] - 2s 1s/step - loss: 0.0478 - val_loss: 0.0370

Epoch 00043: val_loss did not improve from 0.03465
Epoch 44/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0393
2/2 [==============================] - 2s 1s/step - loss: 0.0362 - val_loss: 0.0397

Epoch 00044: val_loss did not improve from 0.03465
Epoch 45/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0350
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0412

Epoch 00045: val_loss did not improve from 0.03465
Epoch 46/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0498
2/2 [==============================] - 2s 1s/step - loss: 0.0531 - val_loss: 0.0696

Epoch 00046: val_loss did not improve from 0.03465
Epoch 47/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0482
2/2 [==============================] - 2s 1s/step - loss: 0.0868 - val_loss: 0.0555

Epoch 00047: val_loss did not improve from 0.03465
Epoch 48/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0685
2/2 [==============================] - 2s 1s/step - loss: 0.0714 - val_loss: 0.0417

Epoch 00048: val_loss did not improve from 0.03465
Epoch 49/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0554
2/2 [==============================] - 2s 1s/step - loss: 0.0475 - val_loss: 0.0495

Epoch 00049: val_loss did not improve from 0.03465

Epoch 00049: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.
Epoch 50/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0739
2/2 [==============================] - 2s 1s/step - loss: 0.0705 - val_loss: 0.0701

Epoch 00050: val_loss did not improve from 0.03465
Epoch 51/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0543
2/2 [==============================] - 2s 1s/step - loss: 0.0594 - val_loss: 0.0568

Epoch 00051: val_loss did not improve from 0.03465
Epoch 52/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0566
2/2 [==============================] - 2s 1s/step - loss: 0.0599 - val_loss: 0.0416

Epoch 00052: val_loss did not improve from 0.03465
Epoch 53/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0556
2/2 [==============================] - 2s 1s/step - loss: 0.0496 - val_loss: 0.0532

Epoch 00053: val_loss did not improve from 0.03465
Epoch 54/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0459
2/2 [==============================] - 2s 1s/step - loss: 0.0385 - val_loss: 0.0422

Epoch 00054: val_loss did not improve from 0.03465
Epoch 55/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0521
2/2 [==============================] - 2s 1s/step - loss: 0.0519 - val_loss: 0.0430

Epoch 00055: val_loss did not improve from 0.03465
Epoch 56/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0568
2/2 [==============================] - 2s 1s/step - loss: 0.0519 - val_loss: 0.0403

Epoch 00056: val_loss did not improve from 0.03465
Epoch 57/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0496
2/2 [==============================] - 2s 1s/step - loss: 0.0477 - val_loss: 0.0429

Epoch 00057: val_loss did not improve from 0.03465
Epoch 58/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0431
2/2 [==============================] - 2s 1s/step - loss: 0.0413 - val_loss: 0.0476

Epoch 00058: val_loss did not improve from 0.03465
Epoch 59/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0499
2/2 [==============================] - 2s 1s/step - loss: 0.0475 - val_loss: 0.0407

Epoch 00059: val_loss did not improve from 0.03465

Epoch 00059: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.
Epoch 60/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0456 - val_loss: 0.0349

Epoch 00060: val_loss did not improve from 0.03465
Epoch 61/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0361
2/2 [==============================] - 2s 1s/step - loss: 0.0408 - val_loss: 0.0357

Epoch 00061: val_loss did not improve from 0.03465
Epoch 62/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0428
2/2 [==============================] - 2s 1s/step - loss: 0.0426 - val_loss: 0.0453

Epoch 00062: val_loss did not improve from 0.03465
Epoch 63/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0270
2/2 [==============================] - 2s 1s/step - loss: 0.0314 - val_loss: 0.0428

Epoch 00063: val_loss did not improve from 0.03465
Epoch 64/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0447
2/2 [==============================] - 2s 1s/step - loss: 0.0447 - val_loss: 0.0454

Epoch 00064: val_loss did not improve from 0.03465
Epoch 65/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0426
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0393

Epoch 00065: val_loss did not improve from 0.03465
Epoch 66/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0389
2/2 [==============================] - 2s 1s/step - loss: 0.0371 - val_loss: 0.0347

Epoch 00066: val_loss improved from 0.03465 to 0.03465, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 67/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0333
2/2 [==============================] - 2s 1s/step - loss: 0.0368 - val_loss: 0.0426

Epoch 00067: val_loss did not improve from 0.03465
Epoch 68/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0442
2/2 [==============================] - 2s 1s/step - loss: 0.0438 - val_loss: 0.0384

Epoch 00068: val_loss did not improve from 0.03465
Epoch 69/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0429
2/2 [==============================] - 2s 1s/step - loss: 0.0372 - val_loss: 0.0398

Epoch 00069: val_loss did not improve from 0.03465
Epoch 70/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0440
2/2 [==============================] - 2s 1s/step - loss: 0.0453 - val_loss: 0.0388

Epoch 00070: val_loss did not improve from 0.03465
Epoch 71/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0438
2/2 [==============================] - 2s 1s/step - loss: 0.0449 - val_loss: 0.0311

Epoch 00071: val_loss improved from 0.03465 to 0.03113, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 72/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0455
2/2 [==============================] - 2s 1s/step - loss: 0.0427 - val_loss: 0.0453

Epoch 00072: val_loss did not improve from 0.03113
Epoch 73/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0386
2/2 [==============================] - 2s 1s/step - loss: 0.0350 - val_loss: 0.0426

Epoch 00073: val_loss did not improve from 0.03113

Epoch 00073: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.
Epoch 74/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0434
2/2 [==============================] - 2s 1s/step - loss: 0.0355 - val_loss: 0.0329

Epoch 00074: val_loss did not improve from 0.03113
Epoch 75/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0316
2/2 [==============================] - 2s 1s/step - loss: 0.0336 - val_loss: 0.0455

Epoch 00075: val_loss did not improve from 0.03113
Epoch 76/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0411 - val_loss: 0.0366

Epoch 00076: val_loss did not improve from 0.03113
Epoch 77/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0405
2/2 [==============================] - 2s 1s/step - loss: 0.0432 - val_loss: 0.0435

Epoch 00077: val_loss did not improve from 0.03113
Epoch 78/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0335
2/2 [==============================] - 2s 1s/step - loss: 0.0400 - val_loss: 0.0425

Epoch 00078: val_loss did not improve from 0.03113
Epoch 79/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0403
2/2 [==============================] - 2s 1s/step - loss: 0.0351 - val_loss: 0.0455

Epoch 00079: val_loss did not improve from 0.03113
Epoch 80/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0456
2/2 [==============================] - 2s 1s/step - loss: 0.0449 - val_loss: 0.0417

Epoch 00080: val_loss did not improve from 0.03113
Epoch 81/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0388
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0404

Epoch 00081: val_loss did not improve from 0.03113
Epoch 82/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0414
2/2 [==============================] - 2s 1s/step - loss: 0.0422 - val_loss: 0.0398

Epoch 00082: val_loss did not improve from 0.03113
Epoch 83/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0418
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0446

Epoch 00083: val_loss did not improve from 0.03113

Epoch 00083: ReduceLROnPlateau reducing learning rate to 4.00000004674439e-08.
Epoch 84/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0372
2/2 [==============================] - 2s 1s/step - loss: 0.0367 - val_loss: 0.0355

Epoch 00084: val_loss did not improve from 0.03113
Epoch 85/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0416
2/2 [==============================] - 2s 1s/step - loss: 0.0424 - val_loss: 0.0413

Epoch 00085: val_loss did not improve from 0.03113
Epoch 86/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0406
2/2 [==============================] - 2s 1s/step - loss: 0.0385 - val_loss: 0.0422

Epoch 00086: val_loss did not improve from 0.03113
Epoch 87/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0421
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0431

Epoch 00087: val_loss did not improve from 0.03113
Epoch 88/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0342
2/2 [==============================] - 2s 1s/step - loss: 0.0386 - val_loss: 0.0345

Epoch 00088: val_loss did not improve from 0.03113
Epoch 89/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0416
2/2 [==============================] - 2s 1s/step - loss: 0.0432 - val_loss: 0.0431

Epoch 00089: val_loss did not improve from 0.03113
Epoch 90/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0431
2/2 [==============================] - 2s 1s/step - loss: 0.0375 - val_loss: 0.0413

Epoch 00090: val_loss did not improve from 0.03113
Epoch 91/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0391
2/2 [==============================] - 2s 1s/step - loss: 0.0389 - val_loss: 0.0413

Epoch 00091: val_loss did not improve from 0.03113
Epoch 92/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0456
2/2 [==============================] - 2s 1s/step - loss: 0.0432 - val_loss: 0.0431

Epoch 00092: val_loss did not improve from 0.03113
Epoch 93/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0345
2/2 [==============================] - 2s 1s/step - loss: 0.0392 - val_loss: 0.0311

Epoch 00093: val_loss did not improve from 0.03113

Epoch 00093: ReduceLROnPlateau reducing learning rate to 3.999999975690117e-09.
Epoch 94/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0310
2/2 [==============================] - 2s 1s/step - loss: 0.0371 - val_loss: 0.0425

Epoch 00094: val_loss did not improve from 0.03113
Epoch 95/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0384
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0424

Epoch 00095: val_loss did not improve from 0.03113
Epoch 96/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0312
2/2 [==============================] - 2s 1s/step - loss: 0.0375 - val_loss: 0.0386

Epoch 00096: val_loss did not improve from 0.03113
Epoch 97/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0388
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0450

Epoch 00097: val_loss did not improve from 0.03113
Epoch 98/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0364
2/2 [==============================] - 2s 1s/step - loss: 0.0366 - val_loss: 0.0350

Epoch 00098: val_loss did not improve from 0.03113
Epoch 99/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0376
2/2 [==============================] - 2s 1s/step - loss: 0.0388 - val_loss: 0.0419

Epoch 00099: val_loss did not improve from 0.03113
Epoch 100/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0372
2/2 [==============================] - 2s 1s/step - loss: 0.0350 - val_loss: 0.0373

Epoch 00100: val_loss did not improve from 0.03113
Epoch 101/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0347
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0414

Epoch 00101: val_loss did not improve from 0.03113
Epoch 102/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0407
2/2 [==============================] - 2s 1s/step - loss: 0.0361 - val_loss: 0.0389

Epoch 00102: val_loss did not improve from 0.03113
Epoch 103/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0390
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0405

Epoch 00103: val_loss did not improve from 0.03113

Epoch 00103: ReduceLROnPlateau reducing learning rate to 3.999999886872274e-10.
Epoch 104/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0260
2/2 [==============================] - 2s 1s/step - loss: 0.0345 - val_loss: 0.0408

Epoch 00104: val_loss did not improve from 0.03113
Epoch 105/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0385
2/2 [==============================] - 2s 1s/step - loss: 0.0417 - val_loss: 0.0443

Epoch 00105: val_loss did not improve from 0.03113
Epoch 106/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0481
2/2 [==============================] - 2s 1s/step - loss: 0.0426 - val_loss: 0.0432

Epoch 00106: val_loss did not improve from 0.03113
Epoch 107/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0427
2/2 [==============================] - 2s 1s/step - loss: 0.0428 - val_loss: 0.0387

Epoch 00107: val_loss did not improve from 0.03113
Epoch 108/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0318
2/2 [==============================] - 2s 1s/step - loss: 0.0392 - val_loss: 0.0407

Epoch 00108: val_loss did not improve from 0.03113
Epoch 109/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0406 - val_loss: 0.0430

Epoch 00109: val_loss did not improve from 0.03113
Epoch 110/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0394
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0415

Epoch 00110: val_loss did not improve from 0.03113
Epoch 111/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0366
2/2 [==============================] - 2s 1s/step - loss: 0.0367 - val_loss: 0.0434

Epoch 00111: val_loss did not improve from 0.03113
Epoch 112/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0409
2/2 [==============================] - 2s 1s/step - loss: 0.0393 - val_loss: 0.0383

Epoch 00112: val_loss did not improve from 0.03113
Epoch 113/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0434
2/2 [==============================] - 2s 1s/step - loss: 0.0423 - val_loss: 0.0411

Epoch 00113: val_loss did not improve from 0.03113

Epoch 00113: ReduceLROnPlateau reducing learning rate to 3.999999775849972e-11.
Epoch 114/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0387
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0438

Epoch 00114: val_loss did not improve from 0.03113
Epoch 115/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0460
2/2 [==============================] - 2s 1s/step - loss: 0.0426 - val_loss: 0.0402

Epoch 00115: val_loss did not improve from 0.03113
Epoch 116/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0324
2/2 [==============================] - 2s 1s/step - loss: 0.0366 - val_loss: 0.0369

Epoch 00116: val_loss did not improve from 0.03113
Epoch 117/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0310
2/2 [==============================] - 2s 1s/step - loss: 0.0366 - val_loss: 0.0355

Epoch 00117: val_loss did not improve from 0.03113
Epoch 118/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0373 - val_loss: 0.0421

Epoch 00118: val_loss did not improve from 0.03113
Epoch 119/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0347
2/2 [==============================] - 2s 1s/step - loss: 0.0390 - val_loss: 0.0369

Epoch 00119: val_loss did not improve from 0.03113
Epoch 120/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0397
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0428

Epoch 00120: val_loss did not improve from 0.03113
Epoch 121/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0429
2/2 [==============================] - 2s 1s/step - loss: 0.0401 - val_loss: 0.0364

Epoch 00121: val_loss did not improve from 0.03113
Epoch 122/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0403
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0348

Epoch 00122: val_loss did not improve from 0.03113
Epoch 123/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0417
2/2 [==============================] - 2s 1s/step - loss: 0.0401 - val_loss: 0.0453

Epoch 00123: val_loss did not improve from 0.03113

Epoch 00123: ReduceLROnPlateau reducing learning rate to 3.999999637072094e-12.
Epoch 124/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0426
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0351

Epoch 00124: val_loss did not improve from 0.03113
Epoch 125/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0415
2/2 [==============================] - 2s 1s/step - loss: 0.0418 - val_loss: 0.0457

Epoch 00125: val_loss did not improve from 0.03113
Epoch 126/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0391
2/2 [==============================] - 2s 1s/step - loss: 0.0380 - val_loss: 0.0424

Epoch 00126: val_loss did not improve from 0.03113
Epoch 127/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0375
2/2 [==============================] - 2s 1s/step - loss: 0.0418 - val_loss: 0.0411

Epoch 00127: val_loss did not improve from 0.03113
Epoch 128/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0465
2/2 [==============================] - 2s 1s/step - loss: 0.0456 - val_loss: 0.0422

Epoch 00128: val_loss did not improve from 0.03113
Epoch 129/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0456
2/2 [==============================] - 2s 1s/step - loss: 0.0400 - val_loss: 0.0366

Epoch 00129: val_loss did not improve from 0.03113
Epoch 130/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0449
2/2 [==============================] - 2s 1s/step - loss: 0.0426 - val_loss: 0.0391

Epoch 00130: val_loss did not improve from 0.03113
Epoch 131/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0392
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0348

Epoch 00131: val_loss did not improve from 0.03113
Epoch 132/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0425
2/2 [==============================] - 2s 1s/step - loss: 0.0433 - val_loss: 0.0404

Epoch 00132: val_loss did not improve from 0.03113
Epoch 133/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0393 - val_loss: 0.0378

Epoch 00133: val_loss did not improve from 0.03113

Epoch 00133: ReduceLROnPlateau reducing learning rate to 3.99999955033592e-13.
Epoch 134/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0433
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0426

Epoch 00134: val_loss did not improve from 0.03113
Epoch 135/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0339
2/2 [==============================] - 2s 1s/step - loss: 0.0369 - val_loss: 0.0363

Epoch 00135: val_loss did not improve from 0.03113
Epoch 136/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0344
2/2 [==============================] - 2s 1s/step - loss: 0.0354 - val_loss: 0.0419

Epoch 00136: val_loss did not improve from 0.03113
Epoch 137/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0446
2/2 [==============================] - 2s 1s/step - loss: 0.0404 - val_loss: 0.0431

Epoch 00137: val_loss did not improve from 0.03113
Epoch 138/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0376
2/2 [==============================] - 2s 1s/step - loss: 0.0391 - val_loss: 0.0373

Epoch 00138: val_loss did not improve from 0.03113
Epoch 139/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0338
2/2 [==============================] - 2s 1s/step - loss: 0.0359 - val_loss: 0.0386

Epoch 00139: val_loss did not improve from 0.03113
Epoch 140/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0418
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0400

Epoch 00140: val_loss did not improve from 0.03113
Epoch 141/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0449
2/2 [==============================] - 2s 1s/step - loss: 0.0393 - val_loss: 0.0365

Epoch 00141: val_loss did not improve from 0.03113
Epoch 142/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0417
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0418

Epoch 00142: val_loss did not improve from 0.03113
Epoch 143/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0291
2/2 [==============================] - 2s 1s/step - loss: 0.0355 - val_loss: 0.0405

Epoch 00143: val_loss did not improve from 0.03113

Epoch 00143: ReduceLROnPlateau reducing learning rate to 3.9999996587561374e-14.
Epoch 144/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0444
2/2 [==============================] - 2s 1s/step - loss: 0.0419 - val_loss: 0.0381

Epoch 00144: val_loss did not improve from 0.03113
Epoch 145/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0402
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0380

Epoch 00145: val_loss did not improve from 0.03113
Epoch 146/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0411
2/2 [==============================] - 2s 1s/step - loss: 0.0377 - val_loss: 0.0397

Epoch 00146: val_loss did not improve from 0.03113
Epoch 147/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0419
2/2 [==============================] - 2s 1s/step - loss: 0.0391 - val_loss: 0.0349

Epoch 00147: val_loss did not improve from 0.03113
Epoch 148/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0442
2/2 [==============================] - 2s 1s/step - loss: 0.0436 - val_loss: 0.0467

Epoch 00148: val_loss did not improve from 0.03113
Epoch 149/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0388 - val_loss: 0.0440

Epoch 00149: val_loss did not improve from 0.03113
Epoch 150/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0425
2/2 [==============================] - 2s 1s/step - loss: 0.0395 - val_loss: 0.0388

Epoch 00150: val_loss did not improve from 0.03113
Epoch 151/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0487
2/2 [==============================] - 2s 1s/step - loss: 0.0451 - val_loss: 0.0414

Epoch 00151: val_loss did not improve from 0.03113
Epoch 152/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0389
2/2 [==============================] - 2s 1s/step - loss: 0.0417 - val_loss: 0.0409

Epoch 00152: val_loss did not improve from 0.03113
Epoch 153/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0317
2/2 [==============================] - 2s 1s/step - loss: 0.0349 - val_loss: 0.0372

Epoch 00153: val_loss did not improve from 0.03113

Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.999999590993501e-15.
Epoch 154/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0370
2/2 [==============================] - 2s 1s/step - loss: 0.0377 - val_loss: 0.0372

Epoch 00154: val_loss did not improve from 0.03113
Epoch 155/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0423
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0388

Epoch 00155: val_loss did not improve from 0.03113
Epoch 156/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0361
2/2 [==============================] - 2s 1s/step - loss: 0.0309 - val_loss: 0.0384

Epoch 00156: val_loss did not improve from 0.03113
Epoch 157/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0452
2/2 [==============================] - 2s 1s/step - loss: 0.0410 - val_loss: 0.0392

Epoch 00157: val_loss did not improve from 0.03113
Epoch 158/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0363
2/2 [==============================] - 2s 1s/step - loss: 0.0356 - val_loss: 0.0416

Epoch 00158: val_loss did not improve from 0.03113
Epoch 159/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0344
2/2 [==============================] - 2s 1s/step - loss: 0.0351 - val_loss: 0.0394

Epoch 00159: val_loss did not improve from 0.03113
Epoch 160/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0429
2/2 [==============================] - 2s 1s/step - loss: 0.0404 - val_loss: 0.0429

Epoch 00160: val_loss did not improve from 0.03113
Epoch 161/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0415
2/2 [==============================] - 2s 1s/step - loss: 0.0384 - val_loss: 0.0406

Epoch 00161: val_loss did not improve from 0.03113
Epoch 162/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0419 - val_loss: 0.0436

Epoch 00162: val_loss did not improve from 0.03113
Epoch 163/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0296
2/2 [==============================] - 2s 1s/step - loss: 0.0380 - val_loss: 0.0360

Epoch 00163: val_loss did not improve from 0.03113
Epoch 164/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0459
2/2 [==============================] - 2s 1s/step - loss: 0.0451 - val_loss: 0.0372

Epoch 00164: val_loss did not improve from 0.03113
Epoch 165/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0389
2/2 [==============================] - 2s 1s/step - loss: 0.0388 - val_loss: 0.0415

Epoch 00165: val_loss did not improve from 0.03113
Epoch 166/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0422
2/2 [==============================] - 2s 1s/step - loss: 0.0439 - val_loss: 0.0439

Epoch 00166: val_loss did not improve from 0.03113

Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.9999995909935016e-16.
Epoch 167/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0351
2/2 [==============================] - 2s 1s/step - loss: 0.0419 - val_loss: 0.0430

Epoch 00167: val_loss did not improve from 0.03113
Epoch 168/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0403
2/2 [==============================] - 2s 1s/step - loss: 0.0405 - val_loss: 0.0379

Epoch 00168: val_loss did not improve from 0.03113
Epoch 169/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0410
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0399

Epoch 00169: val_loss did not improve from 0.03113
Epoch 170/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0388
2/2 [==============================] - 2s 1s/step - loss: 0.0392 - val_loss: 0.0375

Epoch 00170: val_loss did not improve from 0.03113
Epoch 171/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0361
2/2 [==============================] - 2s 1s/step - loss: 0.0390 - val_loss: 0.0344

Epoch 00171: val_loss did not improve from 0.03113
Epoch 172/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0440
2/2 [==============================] - 2s 1s/step - loss: 0.0441 - val_loss: 0.0427

Epoch 00172: val_loss did not improve from 0.03113
Epoch 173/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0374
2/2 [==============================] - 2s 1s/step - loss: 0.0395 - val_loss: 0.0381

Epoch 00173: val_loss did not improve from 0.03113
Epoch 174/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0405
2/2 [==============================] - 2s 1s/step - loss: 0.0367 - val_loss: 0.0416

Epoch 00174: val_loss did not improve from 0.03113
Epoch 175/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0379
2/2 [==============================] - 2s 1s/step - loss: 0.0375 - val_loss: 0.0335

Epoch 00175: val_loss did not improve from 0.03113
Epoch 176/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0327
2/2 [==============================] - 2s 1s/step - loss: 0.0363 - val_loss: 0.0337

Epoch 00176: val_loss did not improve from 0.03113

Epoch 00176: ReduceLROnPlateau reducing learning rate to 3.9999995380539423e-17.
Epoch 177/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0403
2/2 [==============================] - 2s 1s/step - loss: 0.0408 - val_loss: 0.0425

Epoch 00177: val_loss did not improve from 0.03113
Epoch 178/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0366
2/2 [==============================] - 2s 1s/step - loss: 0.0353 - val_loss: 0.0420

Epoch 00178: val_loss did not improve from 0.03113
Epoch 179/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0467
2/2 [==============================] - 2s 1s/step - loss: 0.0407 - val_loss: 0.0400

Epoch 00179: val_loss did not improve from 0.03113
Epoch 180/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0402
2/2 [==============================] - 2s 1s/step - loss: 0.0409 - val_loss: 0.0367

Epoch 00180: val_loss did not improve from 0.03113
Epoch 181/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0277
2/2 [==============================] - 2s 1s/step - loss: 0.0351 - val_loss: 0.0449

Epoch 00181: val_loss did not improve from 0.03113
Epoch 182/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0341
2/2 [==============================] - 2s 1s/step - loss: 0.0343 - val_loss: 0.0389

Epoch 00182: val_loss did not improve from 0.03113
Epoch 183/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0367
2/2 [==============================] - 2s 1s/step - loss: 0.0439 - val_loss: 0.0367

Epoch 00183: val_loss did not improve from 0.03113
Epoch 184/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0393
2/2 [==============================] - 2s 1s/step - loss: 0.0408 - val_loss: 0.0345

Epoch 00184: val_loss did not improve from 0.03113
Epoch 185/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0415
2/2 [==============================] - 2s 1s/step - loss: 0.0440 - val_loss: 0.0426

Epoch 00185: val_loss did not improve from 0.03113
Epoch 186/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0375
2/2 [==============================] - 2s 1s/step - loss: 0.0413 - val_loss: 0.0386

Epoch 00186: val_loss did not improve from 0.03113

Epoch 00186: ReduceLROnPlateau reducing learning rate to 3.999999604228391e-18.
Epoch 187/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0380
2/2 [==============================] - 2s 1s/step - loss: 0.0411 - val_loss: 0.0402

Epoch 00187: val_loss did not improve from 0.03113
Epoch 188/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0451
2/2 [==============================] - 2s 1s/step - loss: 0.0446 - val_loss: 0.0344

Epoch 00188: val_loss did not improve from 0.03113
Epoch 189/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0422
2/2 [==============================] - 2s 1s/step - loss: 0.0435 - val_loss: 0.0415

Epoch 00189: val_loss did not improve from 0.03113
Epoch 190/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0350
2/2 [==============================] - 2s 1s/step - loss: 0.0384 - val_loss: 0.0355

Epoch 00190: val_loss did not improve from 0.03113
Epoch 191/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0469
2/2 [==============================] - 2s 1s/step - loss: 0.0443 - val_loss: 0.0392

Epoch 00191: val_loss did not improve from 0.03113
Epoch 192/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0357
2/2 [==============================] - 2s 1s/step - loss: 0.0410 - val_loss: 0.0374

Epoch 00192: val_loss did not improve from 0.03113
Epoch 193/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0422
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0356

Epoch 00193: val_loss did not improve from 0.03113
Epoch 194/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0459
2/2 [==============================] - 2s 1s/step - loss: 0.0451 - val_loss: 0.0392

Epoch 00194: val_loss did not improve from 0.03113
Epoch 195/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0418
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0426

Epoch 00195: val_loss did not improve from 0.03113
Epoch 196/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0463
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0362

Epoch 00196: val_loss did not improve from 0.03113

Epoch 00196: ReduceLROnPlateau reducing learning rate to 3.999999769664514e-19.
Epoch 197/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0333
2/2 [==============================] - 2s 1s/step - loss: 0.0343 - val_loss: 0.0370

Epoch 00197: val_loss did not improve from 0.03113
Epoch 198/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0371
2/2 [==============================] - 2s 1s/step - loss: 0.0388 - val_loss: 0.0386

Epoch 00198: val_loss did not improve from 0.03113
Epoch 199/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0424
2/2 [==============================] - 2s 1s/step - loss: 0.0419 - val_loss: 0.0381

Epoch 00199: val_loss did not improve from 0.03113
Epoch 200/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0403
2/2 [==============================] - 2s 1s/step - loss: 0.0402 - val_loss: 0.0351

Epoch 00200: val_loss did not improve from 0.03113
Epoch 201/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0437
2/2 [==============================] - 2s 1s/step - loss: 0.0407 - val_loss: 0.0410

Epoch 00201: val_loss did not improve from 0.03113
Epoch 202/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0493
2/2 [==============================] - 2s 1s/step - loss: 0.0436 - val_loss: 0.0392

Epoch 00202: val_loss did not improve from 0.03113
Epoch 203/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0419
2/2 [==============================] - 2s 1s/step - loss: 0.0422 - val_loss: 0.0401

Epoch 00203: val_loss did not improve from 0.03113
Epoch 204/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0331
2/2 [==============================] - 2s 1s/step - loss: 0.0322 - val_loss: 0.0431

Epoch 00204: val_loss did not improve from 0.03113
Epoch 205/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0362
2/2 [==============================] - 2s 1s/step - loss: 0.0376 - val_loss: 0.0415

Epoch 00205: val_loss did not improve from 0.03113
Epoch 206/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0389
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0413

Epoch 00206: val_loss did not improve from 0.03113

Epoch 00206: ReduceLROnPlateau reducing learning rate to 3.99999987306209e-20.
Epoch 207/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0444
2/2 [==============================] - 2s 1s/step - loss: 0.0442 - val_loss: 0.0410

Epoch 00207: val_loss did not improve from 0.03113
Epoch 208/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0285
2/2 [==============================] - 2s 1s/step - loss: 0.0350 - val_loss: 0.0393

Epoch 00208: val_loss did not improve from 0.03113
Epoch 209/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0409
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0410

Epoch 00209: val_loss did not improve from 0.03113
Epoch 210/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0444
2/2 [==============================] - 2s 1s/step - loss: 0.0466 - val_loss: 0.0394

Epoch 00210: val_loss did not improve from 0.03113
Epoch 211/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0461
2/2 [==============================] - 2s 1s/step - loss: 0.0449 - val_loss: 0.0408

Epoch 00211: val_loss did not improve from 0.03113
Epoch 212/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0370
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0405

Epoch 00212: val_loss did not improve from 0.03113
Epoch 213/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0350
2/2 [==============================] - 2s 1s/step - loss: 0.0382 - val_loss: 0.0389

Epoch 00213: val_loss did not improve from 0.03113
Epoch 214/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0351
2/2 [==============================] - 2s 1s/step - loss: 0.0352 - val_loss: 0.0447

Epoch 00214: val_loss did not improve from 0.03113
Epoch 215/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0359
2/2 [==============================] - 2s 1s/step - loss: 0.0373 - val_loss: 0.0394

Epoch 00215: val_loss did not improve from 0.03113
Epoch 216/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0425
2/2 [==============================] - 2s 1s/step - loss: 0.0430 - val_loss: 0.0433

Epoch 00216: val_loss did not improve from 0.03113

Epoch 00216: ReduceLROnPlateau reducing learning rate to 3.99999987306209e-21.
Epoch 217/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0368
2/2 [==============================] - 3s 1s/step - loss: 0.0411 - val_loss: 0.0404

Epoch 00217: val_loss did not improve from 0.03113
Epoch 218/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0333
2/2 [==============================] - 2s 1s/step - loss: 0.0357 - val_loss: 0.0372

Epoch 00218: val_loss did not improve from 0.03113
Epoch 219/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0414
2/2 [==============================] - 2s 1s/step - loss: 0.0393 - val_loss: 0.0463

Epoch 00219: val_loss did not improve from 0.03113
Epoch 220/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0296
2/2 [==============================] - 3s 1s/step - loss: 0.0330 - val_loss: 0.0452

Epoch 00220: val_loss did not improve from 0.03113
Epoch 221/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0411
2/2 [==============================] - 2s 1s/step - loss: 0.0365 - val_loss: 0.0414

Epoch 00221: val_loss did not improve from 0.03113
Epoch 222/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0405
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0386

Epoch 00222: val_loss did not improve from 0.03113
Epoch 223/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0366
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0423

Epoch 00223: val_loss did not improve from 0.03113
Epoch 224/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0421
2/2 [==============================] - 2s 1s/step - loss: 0.0422 - val_loss: 0.0422

Epoch 00224: val_loss did not improve from 0.03113
Epoch 225/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0366
2/2 [==============================] - 2s 1s/step - loss: 0.0384 - val_loss: 0.0391

Epoch 00225: val_loss did not improve from 0.03113
Epoch 226/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0370
2/2 [==============================] - 2s 1s/step - loss: 0.0351 - val_loss: 0.0396

Epoch 00226: val_loss did not improve from 0.03113

Epoch 00226: ReduceLROnPlateau reducing learning rate to 3.99999987306209e-22.
Epoch 227/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0372
2/2 [==============================] - 2s 1s/step - loss: 0.0376 - val_loss: 0.0421

Epoch 00227: val_loss did not improve from 0.03113
Epoch 228/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0397
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0479

Epoch 00228: val_loss did not improve from 0.03113
Epoch 229/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0350
2/2 [==============================] - 2s 1s/step - loss: 0.0406 - val_loss: 0.0415

Epoch 00229: val_loss did not improve from 0.03113
Epoch 230/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0366
2/2 [==============================] - 2s 1s/step - loss: 0.0351 - val_loss: 0.0371

Epoch 00230: val_loss did not improve from 0.03113
Epoch 231/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0367
2/2 [==============================] - 2s 1s/step - loss: 0.0419 - val_loss: 0.0382

Epoch 00231: val_loss did not improve from 0.03113
Epoch 232/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0451
2/2 [==============================] - 2s 1s/step - loss: 0.0431 - val_loss: 0.0367

Epoch 00232: val_loss did not improve from 0.03113
Epoch 233/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0441
2/2 [==============================] - 2s 1s/step - loss: 0.0390 - val_loss: 0.0397

Epoch 00233: val_loss did not improve from 0.03113
Epoch 234/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0359
2/2 [==============================] - 2s 1s/step - loss: 0.0329 - val_loss: 0.0468

Epoch 00234: val_loss did not improve from 0.03113
Epoch 235/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0384
2/2 [==============================] - 2s 1s/step - loss: 0.0365 - val_loss: 0.0450

Epoch 00235: val_loss did not improve from 0.03113
Epoch 236/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0346
2/2 [==============================] - 2s 1s/step - loss: 0.0357 - val_loss: 0.0412

Epoch 00236: val_loss did not improve from 0.03113

Epoch 00236: ReduceLROnPlateau reducing learning rate to 3.9999998730620906e-23.
Epoch 237/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0454
2/2 [==============================] - 2s 1s/step - loss: 0.0395 - val_loss: 0.0414

Epoch 00237: val_loss did not improve from 0.03113
Epoch 238/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0370
2/2 [==============================] - 2s 1s/step - loss: 0.0345 - val_loss: 0.0411

Epoch 00238: val_loss did not improve from 0.03113
Epoch 239/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0425
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0415

Epoch 00239: val_loss did not improve from 0.03113
Epoch 240/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0447
2/2 [==============================] - 2s 1s/step - loss: 0.0434 - val_loss: 0.0352

Epoch 00240: val_loss did not improve from 0.03113
Epoch 241/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0340
2/2 [==============================] - 2s 1s/step - loss: 0.0385 - val_loss: 0.0441

Epoch 00241: val_loss did not improve from 0.03113
Epoch 242/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0416
2/2 [==============================] - 2s 1s/step - loss: 0.0391 - val_loss: 0.0376

Epoch 00242: val_loss did not improve from 0.03113
Epoch 243/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0360
2/2 [==============================] - 2s 1s/step - loss: 0.0389 - val_loss: 0.0421

Epoch 00243: val_loss did not improve from 0.03113
Epoch 244/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0409
2/2 [==============================] - 2s 1s/step - loss: 0.0392 - val_loss: 0.0360

Epoch 00244: val_loss did not improve from 0.03113
Epoch 245/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0446
2/2 [==============================] - 2s 1s/step - loss: 0.0413 - val_loss: 0.0429

Epoch 00245: val_loss did not improve from 0.03113
Epoch 246/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0442
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0443

Epoch 00246: val_loss did not improve from 0.03113

Epoch 00246: ReduceLROnPlateau reducing learning rate to 3.999999999279835e-24.
Epoch 247/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0393
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0439

Epoch 00247: val_loss did not improve from 0.03113
Epoch 248/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0387
2/2 [==============================] - 2s 1s/step - loss: 0.0386 - val_loss: 0.0433

Epoch 00248: val_loss did not improve from 0.03113
Epoch 249/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0438
2/2 [==============================] - 2s 1s/step - loss: 0.0390 - val_loss: 0.0372

Epoch 00249: val_loss did not improve from 0.03113
Epoch 250/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0386
2/2 [==============================] - 2s 1s/step - loss: 0.0359 - val_loss: 0.0362

Epoch 00250: val_loss did not improve from 0.03113
Epoch 251/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0409
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0441

Epoch 00251: val_loss did not improve from 0.03113
Epoch 252/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0460
2/2 [==============================] - 2s 1s/step - loss: 0.0431 - val_loss: 0.0350

Epoch 00252: val_loss did not improve from 0.03113
Epoch 253/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0297
2/2 [==============================] - 2s 1s/step - loss: 0.0358 - val_loss: 0.0449

Epoch 00253: val_loss did not improve from 0.03113
Epoch 254/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0403
2/2 [==============================] - 2s 1s/step - loss: 0.0418 - val_loss: 0.0379

Epoch 00254: val_loss did not improve from 0.03113
Epoch 255/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0353
2/2 [==============================] - 2s 1s/step - loss: 0.0323 - val_loss: 0.0441

Epoch 00255: val_loss did not improve from 0.03113
Epoch 256/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0305
2/2 [==============================] - 2s 1s/step - loss: 0.0340 - val_loss: 0.0455

Epoch 00256: val_loss did not improve from 0.03113

Epoch 00256: ReduceLROnPlateau reducing learning rate to 4.0000000781659255e-25.
Epoch 257/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0442
2/2 [==============================] - 2s 1s/step - loss: 0.0467 - val_loss: 0.0379

Epoch 00257: val_loss did not improve from 0.03113
Epoch 258/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0412
2/2 [==============================] - 3s 1s/step - loss: 0.0407 - val_loss: 0.0462

Epoch 00258: val_loss did not improve from 0.03113
Epoch 259/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0439
2/2 [==============================] - 2s 1s/step - loss: 0.0429 - val_loss: 0.0372

Epoch 00259: val_loss did not improve from 0.03113
Epoch 260/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0376
2/2 [==============================] - 2s 1s/step - loss: 0.0446 - val_loss: 0.0434

Epoch 00260: val_loss did not improve from 0.03113
Epoch 261/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0273
2/2 [==============================] - 2s 1s/step - loss: 0.0350 - val_loss: 0.0369

Epoch 00261: val_loss did not improve from 0.03113
Epoch 262/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0467
2/2 [==============================] - 2s 1s/step - loss: 0.0438 - val_loss: 0.0339

Epoch 00262: val_loss did not improve from 0.03113
Epoch 263/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0408 - val_loss: 0.0369

Epoch 00263: val_loss did not improve from 0.03113
Epoch 264/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0423
2/2 [==============================] - 2s 1s/step - loss: 0.0405 - val_loss: 0.0421

Epoch 00264: val_loss did not improve from 0.03113
Epoch 265/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0319
2/2 [==============================] - 2s 1s/step - loss: 0.0358 - val_loss: 0.0399

Epoch 00265: val_loss did not improve from 0.03113
Epoch 266/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0310
2/2 [==============================] - 2s 1s/step - loss: 0.0401 - val_loss: 0.0392

Epoch 00266: val_loss did not improve from 0.03113

Epoch 00266: ReduceLROnPlateau reducing learning rate to 4.0000000781659256e-26.
Epoch 267/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0395
2/2 [==============================] - 2s 1s/step - loss: 0.0367 - val_loss: 0.0356

Epoch 00267: val_loss did not improve from 0.03113
Epoch 268/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0422
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0382

Epoch 00268: val_loss did not improve from 0.03113
Epoch 269/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0350
2/2 [==============================] - 2s 1s/step - loss: 0.0358 - val_loss: 0.0444

Epoch 00269: val_loss did not improve from 0.03113
Epoch 270/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0288
2/2 [==============================] - 2s 1s/step - loss: 0.0330 - val_loss: 0.0390

Epoch 00270: val_loss did not improve from 0.03113
Epoch 271/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0473
2/2 [==============================] - 2s 1s/step - loss: 0.0421 - val_loss: 0.0454

Epoch 00271: val_loss did not improve from 0.03113
Epoch 272/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0447
2/2 [==============================] - 2s 1s/step - loss: 0.0441 - val_loss: 0.0396

Epoch 00272: val_loss did not improve from 0.03113
Epoch 273/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0403
2/2 [==============================] - 2s 1s/step - loss: 0.0401 - val_loss: 0.0383

Epoch 00273: val_loss did not improve from 0.03113
Epoch 274/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0478
2/2 [==============================] - 2s 1s/step - loss: 0.0468 - val_loss: 0.0430

Epoch 00274: val_loss did not improve from 0.03113
Epoch 275/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0454
2/2 [==============================] - 3s 1s/step - loss: 0.0349 - val_loss: 0.0394

Epoch 00275: val_loss did not improve from 0.03113
Epoch 276/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0397
2/2 [==============================] - 2s 1s/step - loss: 0.0366 - val_loss: 0.0435

Epoch 00276: val_loss did not improve from 0.03113

Epoch 00276: ReduceLROnPlateau reducing learning rate to 3.99999995490641e-27.
Epoch 277/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0348
2/2 [==============================] - 2s 1s/step - loss: 0.0382 - val_loss: 0.0432

Epoch 00277: val_loss did not improve from 0.03113
Epoch 278/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0394
2/2 [==============================] - 3s 1s/step - loss: 0.0398 - val_loss: 0.0360

Epoch 00278: val_loss did not improve from 0.03113
Epoch 279/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0326
2/2 [==============================] - 2s 1s/step - loss: 0.0393 - val_loss: 0.0412

Epoch 00279: val_loss did not improve from 0.03113
Epoch 280/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0433
2/2 [==============================] - 2s 1s/step - loss: 0.0376 - val_loss: 0.0406

Epoch 00280: val_loss did not improve from 0.03113
Epoch 281/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0367
2/2 [==============================] - 2s 1s/step - loss: 0.0338 - val_loss: 0.0303

Epoch 00281: val_loss improved from 0.03113 to 0.03025, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 282/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0340
2/2 [==============================] - 2s 1s/step - loss: 0.0388 - val_loss: 0.0438

Epoch 00282: val_loss did not improve from 0.03025
Epoch 283/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0398
2/2 [==============================] - 2s 1s/step - loss: 0.0418 - val_loss: 0.0414

Epoch 00283: val_loss did not improve from 0.03025
Epoch 284/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0309
2/2 [==============================] - 3s 1s/step - loss: 0.0360 - val_loss: 0.0352

Epoch 00284: val_loss did not improve from 0.03025
Epoch 285/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0481
2/2 [==============================] - 2s 1s/step - loss: 0.0468 - val_loss: 0.0464

Epoch 00285: val_loss did not improve from 0.03025
Epoch 286/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0433
2/2 [==============================] - 3s 1s/step - loss: 0.0455 - val_loss: 0.0416

Epoch 00286: val_loss did not improve from 0.03025

Epoch 00286: ReduceLROnPlateau reducing learning rate to 4.0000001089808047e-28.
Epoch 287/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0391
2/2 [==============================] - 2s 1s/step - loss: 0.0401 - val_loss: 0.0411

Epoch 00287: val_loss did not improve from 0.03025
Epoch 288/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0448
2/2 [==============================] - 2s 1s/step - loss: 0.0440 - val_loss: 0.0402

Epoch 00288: val_loss did not improve from 0.03025
Epoch 289/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0449
2/2 [==============================] - 2s 1s/step - loss: 0.0422 - val_loss: 0.0480

Epoch 00289: val_loss did not improve from 0.03025
Epoch 290/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0428 - val_loss: 0.0432

Epoch 00290: val_loss did not improve from 0.03025
Epoch 291/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0373
2/2 [==============================] - 2s 1s/step - loss: 0.0404 - val_loss: 0.0420

Epoch 00291: val_loss did not improve from 0.03025
Epoch 292/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0370
2/2 [==============================] - 2s 1s/step - loss: 0.0364 - val_loss: 0.0398

Epoch 00292: val_loss did not improve from 0.03025
Epoch 293/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0489
2/2 [==============================] - 2s 1s/step - loss: 0.0460 - val_loss: 0.0397

Epoch 00293: val_loss did not improve from 0.03025
Epoch 294/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0479
2/2 [==============================] - 2s 1s/step - loss: 0.0458 - val_loss: 0.0440

Epoch 00294: val_loss did not improve from 0.03025
Epoch 295/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0333
2/2 [==============================] - 2s 1s/step - loss: 0.0335 - val_loss: 0.0379

Epoch 00295: val_loss did not improve from 0.03025
Epoch 296/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0382
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0355

Epoch 00296: val_loss did not improve from 0.03025

Epoch 00296: ReduceLROnPlateau reducing learning rate to 4.0000000126843074e-29.
Epoch 297/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0463
2/2 [==============================] - 2s 1s/step - loss: 0.0439 - val_loss: 0.0429

Epoch 00297: val_loss did not improve from 0.03025
Epoch 298/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0363
2/2 [==============================] - 2s 1s/step - loss: 0.0375 - val_loss: 0.0371

Epoch 00298: val_loss did not improve from 0.03025
Epoch 299/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0495
2/2 [==============================] - 2s 1s/step - loss: 0.0410 - val_loss: 0.0389

Epoch 00299: val_loss did not improve from 0.03025
Epoch 300/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0421
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0412

Epoch 00300: val_loss did not improve from 0.03025
Epoch 301/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0362
2/2 [==============================] - 2s 1s/step - loss: 0.0386 - val_loss: 0.0423

Epoch 00301: val_loss did not improve from 0.03025
Epoch 302/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0438
2/2 [==============================] - 2s 1s/step - loss: 0.0391 - val_loss: 0.0423

Epoch 00302: val_loss did not improve from 0.03025
Epoch 303/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0339
2/2 [==============================] - 2s 1s/step - loss: 0.0363 - val_loss: 0.0435

Epoch 00303: val_loss did not improve from 0.03025
Epoch 304/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0514
2/2 [==============================] - 3s 1s/step - loss: 0.0409 - val_loss: 0.0467

Epoch 00304: val_loss did not improve from 0.03025
Epoch 305/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0363
2/2 [==============================] - 2s 1s/step - loss: 0.0390 - val_loss: 0.0393

Epoch 00305: val_loss did not improve from 0.03025
Epoch 306/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0439
2/2 [==============================] - 3s 1s/step - loss: 0.0437 - val_loss: 0.0396

Epoch 00306: val_loss did not improve from 0.03025

Epoch 00306: ReduceLROnPlateau reducing learning rate to 4.0000000126843074e-30.
Epoch 307/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0412
2/2 [==============================] - 2s 1s/step - loss: 0.0422 - val_loss: 0.0415

Epoch 00307: val_loss did not improve from 0.03025
Epoch 308/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0391
2/2 [==============================] - 2s 1s/step - loss: 0.0380 - val_loss: 0.0433

Epoch 00308: val_loss did not improve from 0.03025
Epoch 309/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0429
2/2 [==============================] - 2s 1s/step - loss: 0.0418 - val_loss: 0.0411

Epoch 00309: val_loss did not improve from 0.03025
Epoch 310/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0474
2/2 [==============================] - 2s 1s/step - loss: 0.0461 - val_loss: 0.0438

Epoch 00310: val_loss did not improve from 0.03025
Epoch 311/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0429
2/2 [==============================] - 2s 1s/step - loss: 0.0404 - val_loss: 0.0398

Epoch 00311: val_loss did not improve from 0.03025
Epoch 312/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0374
2/2 [==============================] - 2s 1s/step - loss: 0.0367 - val_loss: 0.0384

Epoch 00312: val_loss did not improve from 0.03025
Epoch 313/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0399
2/2 [==============================] - 3s 1s/step - loss: 0.0416 - val_loss: 0.0420

Epoch 00313: val_loss did not improve from 0.03025
Epoch 314/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0463
2/2 [==============================] - 2s 1s/step - loss: 0.0420 - val_loss: 0.0445

Epoch 00314: val_loss did not improve from 0.03025
Epoch 315/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0369
2/2 [==============================] - 3s 1s/step - loss: 0.0413 - val_loss: 0.0404

Epoch 00315: val_loss did not improve from 0.03025
Epoch 316/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0489
2/2 [==============================] - 3s 1s/step - loss: 0.0471 - val_loss: 0.0367

Epoch 00316: val_loss did not improve from 0.03025

Epoch 00316: ReduceLROnPlateau reducing learning rate to 4.000000012684308e-31.
Epoch 317/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0375
2/2 [==============================] - 3s 1s/step - loss: 0.0420 - val_loss: 0.0442

Epoch 00317: val_loss did not improve from 0.03025
Epoch 318/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0423
2/2 [==============================] - 2s 1s/step - loss: 0.0418 - val_loss: 0.0420

Epoch 00318: val_loss did not improve from 0.03025
Epoch 319/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0450
2/2 [==============================] - 2s 1s/step - loss: 0.0393 - val_loss: 0.0453

Epoch 00319: val_loss did not improve from 0.03025
Epoch 320/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0368
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0403

Epoch 00320: val_loss did not improve from 0.03025
Epoch 321/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0483
2/2 [==============================] - 2s 1s/step - loss: 0.0429 - val_loss: 0.0395

Epoch 00321: val_loss did not improve from 0.03025
Epoch 322/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0374
2/2 [==============================] - 2s 1s/step - loss: 0.0369 - val_loss: 0.0339

Epoch 00322: val_loss did not improve from 0.03025
Epoch 323/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0392
2/2 [==============================] - 2s 1s/step - loss: 0.0367 - val_loss: 0.0384

Epoch 00323: val_loss did not improve from 0.03025
Epoch 324/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0402
2/2 [==============================] - 2s 1s/step - loss: 0.0395 - val_loss: 0.0398

Epoch 00324: val_loss did not improve from 0.03025
Epoch 325/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0338
2/2 [==============================] - 2s 1s/step - loss: 0.0387 - val_loss: 0.0353

Epoch 00325: val_loss did not improve from 0.03025
Epoch 326/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0458
2/2 [==============================] - 2s 1s/step - loss: 0.0454 - val_loss: 0.0454

Epoch 00326: val_loss did not improve from 0.03025

Epoch 00326: ReduceLROnPlateau reducing learning rate to 3.9999999186447594e-32.
Epoch 327/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0396
2/2 [==============================] - 2s 1s/step - loss: 0.0407 - val_loss: 0.0456

Epoch 00327: val_loss did not improve from 0.03025
Epoch 328/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0478
2/2 [==============================] - 2s 1s/step - loss: 0.0410 - val_loss: 0.0425

Epoch 00328: val_loss did not improve from 0.03025
Epoch 329/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0402
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0385

Epoch 00329: val_loss did not improve from 0.03025
Epoch 330/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0410
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0355

Epoch 00330: val_loss did not improve from 0.03025
Epoch 331/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0375
2/2 [==============================] - 3s 1s/step - loss: 0.0418 - val_loss: 0.0397

Epoch 00331: val_loss did not improve from 0.03025
Epoch 332/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0474
2/2 [==============================] - 3s 1s/step - loss: 0.0415 - val_loss: 0.0399

Epoch 00332: val_loss did not improve from 0.03025
Epoch 333/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0328
2/2 [==============================] - 3s 1s/step - loss: 0.0389 - val_loss: 0.0428

Epoch 00333: val_loss did not improve from 0.03025
Epoch 334/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0369
2/2 [==============================] - 2s 1s/step - loss: 0.0420 - val_loss: 0.0382

Epoch 00334: val_loss did not improve from 0.03025
Epoch 335/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0353
2/2 [==============================] - 2s 1s/step - loss: 0.0411 - val_loss: 0.0373

Epoch 00335: val_loss did not improve from 0.03025
Epoch 336/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0364
2/2 [==============================] - 2s 1s/step - loss: 0.0373 - val_loss: 0.0403

Epoch 00336: val_loss did not improve from 0.03025

Epoch 00336: ReduceLROnPlateau reducing learning rate to 3.999999801095325e-33.
Epoch 337/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0387
2/2 [==============================] - 2s 1s/step - loss: 0.0341 - val_loss: 0.0382

Epoch 00337: val_loss did not improve from 0.03025
Epoch 338/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0451
2/2 [==============================] - 2s 1s/step - loss: 0.0448 - val_loss: 0.0381

Epoch 00338: val_loss did not improve from 0.03025
Epoch 339/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0441
2/2 [==============================] - 2s 1s/step - loss: 0.0420 - val_loss: 0.0420

Epoch 00339: val_loss did not improve from 0.03025
Epoch 340/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0381
2/2 [==============================] - 3s 1s/step - loss: 0.0376 - val_loss: 0.0384

Epoch 00340: val_loss did not improve from 0.03025
Epoch 341/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0366
2/2 [==============================] - 2s 1s/step - loss: 0.0372 - val_loss: 0.0457

Epoch 00341: val_loss did not improve from 0.03025
Epoch 342/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0380
2/2 [==============================] - 2s 1s/step - loss: 0.0435 - val_loss: 0.0427

Epoch 00342: val_loss did not improve from 0.03025
Epoch 343/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0455
2/2 [==============================] - 2s 1s/step - loss: 0.0436 - val_loss: 0.0404

Epoch 00343: val_loss did not improve from 0.03025
Epoch 344/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0429
2/2 [==============================] - 3s 1s/step - loss: 0.0447 - val_loss: 0.0376

Epoch 00344: val_loss did not improve from 0.03025
Epoch 345/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0383
2/2 [==============================] - 2s 1s/step - loss: 0.0383 - val_loss: 0.0389

Epoch 00345: val_loss did not improve from 0.03025
Epoch 346/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0474
2/2 [==============================] - 2s 1s/step - loss: 0.0456 - val_loss: 0.0395

Epoch 00346: val_loss did not improve from 0.03025

Epoch 00346: ReduceLROnPlateau reducing learning rate to 3.999999727626927e-34.
Epoch 347/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0331
2/2 [==============================] - 3s 1s/step - loss: 0.0381 - val_loss: 0.0436

Epoch 00347: val_loss did not improve from 0.03025
Epoch 348/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0446
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0332

Epoch 00348: val_loss did not improve from 0.03025
Epoch 349/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0414
2/2 [==============================] - 2s 1s/step - loss: 0.0347 - val_loss: 0.0380

Epoch 00349: val_loss did not improve from 0.03025
Epoch 350/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0328
2/2 [==============================] - 2s 1s/step - loss: 0.0373 - val_loss: 0.0458

Epoch 00350: val_loss did not improve from 0.03025
Epoch 351/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0410
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0396

Epoch 00351: val_loss did not improve from 0.03025
Epoch 352/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0403
2/2 [==============================] - 2s 1s/step - loss: 0.0427 - val_loss: 0.0353

Epoch 00352: val_loss did not improve from 0.03025
Epoch 353/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0325
2/2 [==============================] - 3s 1s/step - loss: 0.0333 - val_loss: 0.0375

Epoch 00353: val_loss did not improve from 0.03025
Epoch 354/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0362
2/2 [==============================] - 2s 1s/step - loss: 0.0369 - val_loss: 0.0381

Epoch 00354: val_loss did not improve from 0.03025
Epoch 355/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0465
2/2 [==============================] - 3s 1s/step - loss: 0.0419 - val_loss: 0.0372

Epoch 00355: val_loss did not improve from 0.03025
Epoch 356/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0393
2/2 [==============================] - 2s 1s/step - loss: 0.0347 - val_loss: 0.0392

Epoch 00356: val_loss did not improve from 0.03025

Epoch 00356: ReduceLROnPlateau reducing learning rate to 3.9999997276269275e-35.
Epoch 357/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0423
2/2 [==============================] - 2s 1s/step - loss: 0.0374 - val_loss: 0.0426

Epoch 00357: val_loss did not improve from 0.03025
Epoch 358/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0343
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0412

Epoch 00358: val_loss did not improve from 0.03025
Epoch 359/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0400
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0432

Epoch 00359: val_loss did not improve from 0.03025
Epoch 360/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0440
2/2 [==============================] - 3s 1s/step - loss: 0.0405 - val_loss: 0.0396

Epoch 00360: val_loss did not improve from 0.03025
Epoch 361/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0316
2/2 [==============================] - 2s 1s/step - loss: 0.0388 - val_loss: 0.0373

Epoch 00361: val_loss did not improve from 0.03025
Epoch 362/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0393
2/2 [==============================] - 3s 1s/step - loss: 0.0394 - val_loss: 0.0375

Epoch 00362: val_loss did not improve from 0.03025
Epoch 363/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0320
2/2 [==============================] - 2s 1s/step - loss: 0.0375 - val_loss: 0.0422

Epoch 00363: val_loss did not improve from 0.03025
Epoch 364/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0443
2/2 [==============================] - 2s 1s/step - loss: 0.0427 - val_loss: 0.0382

Epoch 00364: val_loss did not improve from 0.03025
Epoch 365/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0472
2/2 [==============================] - 2s 1s/step - loss: 0.0449 - val_loss: 0.0430

Epoch 00365: val_loss did not improve from 0.03025
Epoch 366/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0364
2/2 [==============================] - 3s 1s/step - loss: 0.0401 - val_loss: 0.0421

Epoch 00366: val_loss did not improve from 0.03025

Epoch 00366: ReduceLROnPlateau reducing learning rate to 3.9999997850241124e-36.
Epoch 367/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0446
2/2 [==============================] - 2s 1s/step - loss: 0.0395 - val_loss: 0.0406

Epoch 00367: val_loss did not improve from 0.03025
Epoch 368/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0321
2/2 [==============================] - 3s 1s/step - loss: 0.0313 - val_loss: 0.0349

Epoch 00368: val_loss did not improve from 0.03025
Epoch 369/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0457
2/2 [==============================] - 2s 1s/step - loss: 0.0460 - val_loss: 0.0436

Epoch 00369: val_loss did not improve from 0.03025
Epoch 370/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0364
2/2 [==============================] - 2s 1s/step - loss: 0.0408 - val_loss: 0.0427

Epoch 00370: val_loss did not improve from 0.03025
Epoch 371/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0431
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0425

Epoch 00371: val_loss did not improve from 0.03025
Epoch 372/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0400
2/2 [==============================] - 2s 1s/step - loss: 0.0389 - val_loss: 0.0415

Epoch 00372: val_loss did not improve from 0.03025
Epoch 373/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0289
2/2 [==============================] - 2s 1s/step - loss: 0.0355 - val_loss: 0.0362

Epoch 00373: val_loss did not improve from 0.03025
Epoch 374/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0442
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0457

Epoch 00374: val_loss did not improve from 0.03025
Epoch 375/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0348
2/2 [==============================] - 2s 1s/step - loss: 0.0347 - val_loss: 0.0453

Epoch 00375: val_loss did not improve from 0.03025
Epoch 376/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0313
2/2 [==============================] - 2s 1s/step - loss: 0.0331 - val_loss: 0.0392

Epoch 00376: val_loss did not improve from 0.03025

Epoch 00376: ReduceLROnPlateau reducing learning rate to 3.999999785024112e-37.
Epoch 377/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0387
2/2 [==============================] - 2s 1s/step - loss: 0.0375 - val_loss: 0.0356

Epoch 00377: val_loss did not improve from 0.03025
Epoch 378/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0401
2/2 [==============================] - 2s 1s/step - loss: 0.0404 - val_loss: 0.0405

Epoch 00378: val_loss did not improve from 0.03025
Epoch 379/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0443
2/2 [==============================] - 2s 1s/step - loss: 0.0434 - val_loss: 0.0408

Epoch 00379: val_loss did not improve from 0.03025
Epoch 380/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0439 - val_loss: 0.0373

Epoch 00380: val_loss did not improve from 0.03025
Epoch 381/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0408
2/2 [==============================] - 2s 1s/step - loss: 0.0443 - val_loss: 0.0357

Epoch 00381: val_loss did not improve from 0.03025
Epoch 382/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0383
2/2 [==============================] - 2s 1s/step - loss: 0.0382 - val_loss: 0.0408

Epoch 00382: val_loss did not improve from 0.03025
Epoch 383/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0446
2/2 [==============================] - 2s 1s/step - loss: 0.0432 - val_loss: 0.0431

Epoch 00383: val_loss did not improve from 0.03025
Epoch 384/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0399
2/2 [==============================] - 2s 1s/step - loss: 0.0407 - val_loss: 0.0343

Epoch 00384: val_loss did not improve from 0.03025
Epoch 385/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0372
2/2 [==============================] - 2s 1s/step - loss: 0.0442 - val_loss: 0.0430

Epoch 00385: val_loss did not improve from 0.03025
Epoch 386/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0352
2/2 [==============================] - 2s 1s/step - loss: 0.0418 - val_loss: 0.0402

Epoch 00386: val_loss did not improve from 0.03025

Epoch 00386: ReduceLROnPlateau reducing learning rate to 3.999999964390316e-38.
Epoch 387/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0365
2/2 [==============================] - 3s 1s/step - loss: 0.0352 - val_loss: 0.0379

Epoch 00387: val_loss did not improve from 0.03025
Epoch 388/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0407
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0406

Epoch 00388: val_loss did not improve from 0.03025
Epoch 389/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0370
2/2 [==============================] - 2s 1s/step - loss: 0.0388 - val_loss: 0.0448

Epoch 00389: val_loss did not improve from 0.03025
Epoch 390/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0387
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0396

Epoch 00390: val_loss did not improve from 0.03025
Epoch 391/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0443
2/2 [==============================] - 2s 1s/step - loss: 0.0451 - val_loss: 0.0376

Epoch 00391: val_loss did not improve from 0.03025
Epoch 392/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0391
2/2 [==============================] - 2s 1s/step - loss: 0.0439 - val_loss: 0.0409

Epoch 00392: val_loss did not improve from 0.03025
Epoch 393/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0447
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0450

Epoch 00393: val_loss did not improve from 0.03025
Epoch 394/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0411
2/2 [==============================] - 2s 1s/step - loss: 0.0410 - val_loss: 0.0395

Epoch 00394: val_loss did not improve from 0.03025
Epoch 395/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0400
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0395

Epoch 00395: val_loss did not improve from 0.03025
Epoch 396/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0310
2/2 [==============================] - 2s 1s/step - loss: 0.0349 - val_loss: 0.0397

Epoch 00396: val_loss did not improve from 0.03025

Epoch 00396: ReduceLROnPlateau reducing learning rate to 4.000000020442255e-39.
Epoch 397/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0468
2/2 [==============================] - 2s 1s/step - loss: 0.0437 - val_loss: 0.0397

Epoch 00397: val_loss did not improve from 0.03025
Epoch 398/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0386
2/2 [==============================] - 2s 1s/step - loss: 0.0422 - val_loss: 0.0385

Epoch 00398: val_loss did not improve from 0.03025
Epoch 399/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0404
2/2 [==============================] - 2s 1s/step - loss: 0.0405 - val_loss: 0.0396

Epoch 00399: val_loss did not improve from 0.03025
Epoch 400/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0431
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0326

Epoch 00400: val_loss did not improve from 0.03025
Epoch 401/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0363
2/2 [==============================] - 2s 1s/step - loss: 0.0393 - val_loss: 0.0437

Epoch 00401: val_loss did not improve from 0.03025
Epoch 402/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0467
2/2 [==============================] - 2s 1s/step - loss: 0.0454 - val_loss: 0.0336

Epoch 00402: val_loss did not improve from 0.03025
Epoch 403/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0391
2/2 [==============================] - 2s 1s/step - loss: 0.0391 - val_loss: 0.0406

Epoch 00403: val_loss did not improve from 0.03025
Epoch 404/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0449
2/2 [==============================] - 2s 1s/step - loss: 0.0435 - val_loss: 0.0416

Epoch 00404: val_loss did not improve from 0.03025
Epoch 405/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0423 - val_loss: 0.0420

Epoch 00405: val_loss did not improve from 0.03025
Epoch 406/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0402
2/2 [==============================] - 2s 1s/step - loss: 0.0382 - val_loss: 0.0453

Epoch 00406: val_loss did not improve from 0.03025

Epoch 00406: ReduceLROnPlateau reducing learning rate to 3.999999459922869e-40.
Epoch 407/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0368
2/2 [==============================] - 2s 1s/step - loss: 0.0362 - val_loss: 0.0321

Epoch 00407: val_loss did not improve from 0.03025
Epoch 408/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0343
2/2 [==============================] - 3s 1s/step - loss: 0.0344 - val_loss: 0.0322

Epoch 00408: val_loss did not improve from 0.03025
Epoch 409/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0465
2/2 [==============================] - 2s 1s/step - loss: 0.0444 - val_loss: 0.0416

Epoch 00409: val_loss did not improve from 0.03025
Epoch 410/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0418
2/2 [==============================] - 2s 1s/step - loss: 0.0421 - val_loss: 0.0407

Epoch 00410: val_loss did not improve from 0.03025
Epoch 411/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0317
2/2 [==============================] - 2s 1s/step - loss: 0.0395 - val_loss: 0.0403

Epoch 00411: val_loss did not improve from 0.03025
Epoch 412/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0367
2/2 [==============================] - 3s 1s/step - loss: 0.0348 - val_loss: 0.0377

Epoch 00412: val_loss did not improve from 0.03025
Epoch 413/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0371
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0425

Epoch 00413: val_loss did not improve from 0.03025
Epoch 414/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0361
2/2 [==============================] - 3s 1s/step - loss: 0.0376 - val_loss: 0.0389

Epoch 00414: val_loss did not improve from 0.03025
Epoch 415/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0368
2/2 [==============================] - 2s 1s/step - loss: 0.0419 - val_loss: 0.0449

Epoch 00415: val_loss did not improve from 0.03025
Epoch 416/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0334
2/2 [==============================] - 2s 1s/step - loss: 0.0372 - val_loss: 0.0417

Epoch 00416: val_loss did not improve from 0.03025

Epoch 00416: ReduceLROnPlateau reducing learning rate to 4.0000064664151903e-41.
Epoch 417/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0428
2/2 [==============================] - 2s 1s/step - loss: 0.0392 - val_loss: 0.0395

Epoch 00417: val_loss did not improve from 0.03025
Epoch 418/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0333
2/2 [==============================] - 2s 1s/step - loss: 0.0387 - val_loss: 0.0388

Epoch 00418: val_loss did not improve from 0.03025
Epoch 419/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0337
2/2 [==============================] - 2s 1s/step - loss: 0.0359 - val_loss: 0.0432

Epoch 00419: val_loss did not improve from 0.03025
Epoch 420/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0453
2/2 [==============================] - 2s 1s/step - loss: 0.0444 - val_loss: 0.0416

Epoch 00420: val_loss did not improve from 0.03025
Epoch 421/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0419
2/2 [==============================] - 2s 1s/step - loss: 0.0404 - val_loss: 0.0335

Epoch 00421: val_loss did not improve from 0.03025
Epoch 422/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0368
2/2 [==============================] - 3s 1s/step - loss: 0.0345 - val_loss: 0.0409

Epoch 00422: val_loss did not improve from 0.03025
Epoch 423/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0345
2/2 [==============================] - 2s 1s/step - loss: 0.0321 - val_loss: 0.0321

Epoch 00423: val_loss did not improve from 0.03025
Epoch 424/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0375 - val_loss: 0.0477

Epoch 00424: val_loss did not improve from 0.03025
Epoch 425/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0352
2/2 [==============================] - 2s 1s/step - loss: 0.0373 - val_loss: 0.0382

Epoch 00425: val_loss did not improve from 0.03025
Epoch 426/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0438 - val_loss: 0.0361

Epoch 00426: val_loss did not improve from 0.03025

Epoch 00426: ReduceLROnPlateau reducing learning rate to 4.0000064664151903e-42.
Epoch 427/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0396
2/2 [==============================] - 2s 1s/step - loss: 0.0426 - val_loss: 0.0413

Epoch 00427: val_loss did not improve from 0.03025
Epoch 428/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0311
2/2 [==============================] - 2s 1s/step - loss: 0.0363 - val_loss: 0.0400

Epoch 00428: val_loss did not improve from 0.03025
Epoch 429/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0378
2/2 [==============================] - 2s 1s/step - loss: 0.0358 - val_loss: 0.0363

Epoch 00429: val_loss did not improve from 0.03025
Epoch 430/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0379
2/2 [==============================] - 2s 1s/step - loss: 0.0421 - val_loss: 0.0411

Epoch 00430: val_loss did not improve from 0.03025
Epoch 431/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0356
2/2 [==============================] - 2s 1s/step - loss: 0.0340 - val_loss: 0.0330

Epoch 00431: val_loss did not improve from 0.03025
Epoch 432/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0320
2/2 [==============================] - 2s 1s/step - loss: 0.0344 - val_loss: 0.0387

Epoch 00432: val_loss did not improve from 0.03025
Epoch 433/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0364
2/2 [==============================] - 2s 1s/step - loss: 0.0348 - val_loss: 0.0448

Epoch 00433: val_loss did not improve from 0.03025
Epoch 434/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0434
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0374

Epoch 00434: val_loss did not improve from 0.03025
Epoch 435/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0376
2/2 [==============================] - 2s 1s/step - loss: 0.0405 - val_loss: 0.0354

Epoch 00435: val_loss did not improve from 0.03025
Epoch 436/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0361
2/2 [==============================] - 2s 1s/step - loss: 0.0359 - val_loss: 0.0394

Epoch 00436: val_loss did not improve from 0.03025

Epoch 00436: ReduceLROnPlateau reducing learning rate to 3.9993058171830284e-43.
Epoch 437/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0396
2/2 [==============================] - 2s 1s/step - loss: 0.0369 - val_loss: 0.0451

Epoch 00437: val_loss did not improve from 0.03025
Epoch 438/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0432 - val_loss: 0.0445

Epoch 00438: val_loss did not improve from 0.03025
Epoch 439/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0370
2/2 [==============================] - 2s 1s/step - loss: 0.0353 - val_loss: 0.0391

Epoch 00439: val_loss did not improve from 0.03025
Epoch 440/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0328
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0415

Epoch 00440: val_loss did not improve from 0.03025
Epoch 441/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0377
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0433

Epoch 00441: val_loss did not improve from 0.03025
Epoch 442/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0370
2/2 [==============================] - 2s 1s/step - loss: 0.0386 - val_loss: 0.0402

Epoch 00442: val_loss did not improve from 0.03025
Epoch 443/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0280
2/2 [==============================] - 2s 1s/step - loss: 0.0338 - val_loss: 0.0454

Epoch 00443: val_loss did not improve from 0.03025
Epoch 444/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0366
2/2 [==============================] - 2s 1s/step - loss: 0.0385 - val_loss: 0.0405

Epoch 00444: val_loss did not improve from 0.03025
Epoch 445/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0377
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0440

Epoch 00445: val_loss did not improve from 0.03025
Epoch 446/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0464
2/2 [==============================] - 2s 1s/step - loss: 0.0441 - val_loss: 0.0337

Epoch 00446: val_loss did not improve from 0.03025

Epoch 00446: ReduceLROnPlateau reducing learning rate to 3.9937006233257287e-44.
Epoch 447/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0439
2/2 [==============================] - 2s 1s/step - loss: 0.0462 - val_loss: 0.0402

Epoch 00447: val_loss did not improve from 0.03025
Epoch 448/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0364
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0451

Epoch 00448: val_loss did not improve from 0.03025
Epoch 449/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0486
2/2 [==============================] - 2s 1s/step - loss: 0.0367 - val_loss: 0.0310

Epoch 00449: val_loss did not improve from 0.03025
Epoch 450/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0345
2/2 [==============================] - 2s 1s/step - loss: 0.0393 - val_loss: 0.0404

Epoch 00450: val_loss did not improve from 0.03025
Epoch 451/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0425
2/2 [==============================] - 2s 1s/step - loss: 0.0420 - val_loss: 0.0409

Epoch 00451: val_loss did not improve from 0.03025
Epoch 452/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0440 - val_loss: 0.0410

Epoch 00452: val_loss did not improve from 0.03025
Epoch 453/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0408
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0422

Epoch 00453: val_loss did not improve from 0.03025
Epoch 454/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0349
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0419

Epoch 00454: val_loss did not improve from 0.03025
Epoch 455/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0410
2/2 [==============================] - 2s 1s/step - loss: 0.0362 - val_loss: 0.0424

Epoch 00455: val_loss did not improve from 0.03025
Epoch 456/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0413
2/2 [==============================] - 2s 1s/step - loss: 0.0442 - val_loss: 0.0404

Epoch 00456: val_loss did not improve from 0.03025

Epoch 00456: ReduceLROnPlateau reducing learning rate to 3.923635700109488e-45.
Epoch 457/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0443
2/2 [==============================] - 2s 1s/step - loss: 0.0445 - val_loss: 0.0381

Epoch 00457: val_loss did not improve from 0.03025
Epoch 458/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0362 - val_loss: 0.0407

Epoch 00458: val_loss did not improve from 0.03025
Epoch 459/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0402
2/2 [==============================] - 2s 1s/step - loss: 0.0371 - val_loss: 0.0401

Epoch 00459: val_loss did not improve from 0.03025
Epoch 460/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0401
2/2 [==============================] - 2s 1s/step - loss: 0.0409 - val_loss: 0.0349

Epoch 00460: val_loss did not improve from 0.03025
Epoch 461/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0403
2/2 [==============================] - 2s 1s/step - loss: 0.0409 - val_loss: 0.0422

Epoch 00461: val_loss did not improve from 0.03025
Epoch 462/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0380
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0382

Epoch 00462: val_loss did not improve from 0.03025
Epoch 463/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0327
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0415

Epoch 00463: val_loss did not improve from 0.03025
Epoch 464/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0433
2/2 [==============================] - 2s 1s/step - loss: 0.0414 - val_loss: 0.0399

Epoch 00464: val_loss did not improve from 0.03025
Epoch 465/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0463
2/2 [==============================] - 2s 1s/step - loss: 0.0435 - val_loss: 0.0347

Epoch 00465: val_loss did not improve from 0.03025
Epoch 466/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0486
2/2 [==============================] - 2s 1s/step - loss: 0.0436 - val_loss: 0.0412

Epoch 00466: val_loss did not improve from 0.03025

Epoch 00466: ReduceLROnPlateau reducing learning rate to 4.203895392974452e-46.
Epoch 467/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0405
2/2 [==============================] - 2s 1s/step - loss: 0.0402 - val_loss: 0.0372

Epoch 00467: val_loss did not improve from 0.03025
Epoch 468/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0393
2/2 [==============================] - 2s 1s/step - loss: 0.0374 - val_loss: 0.0394

Epoch 00468: val_loss did not improve from 0.03025
Epoch 469/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0451
2/2 [==============================] - 2s 1s/step - loss: 0.0446 - val_loss: 0.0425

Epoch 00469: val_loss did not improve from 0.03025
Epoch 470/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0330
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0400

Epoch 00470: val_loss did not improve from 0.03025
Epoch 471/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0470
2/2 [==============================] - 2s 1s/step - loss: 0.0438 - val_loss: 0.0360

Epoch 00471: val_loss did not improve from 0.03025
Epoch 472/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0429
2/2 [==============================] - 2s 1s/step - loss: 0.0432 - val_loss: 0.0390

Epoch 00472: val_loss did not improve from 0.03025
Epoch 473/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0468
2/2 [==============================] - 2s 1s/step - loss: 0.0436 - val_loss: 0.0398

Epoch 00473: val_loss did not improve from 0.03025
Epoch 474/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0437
2/2 [==============================] - 2s 1s/step - loss: 0.0449 - val_loss: 0.0428

Epoch 00474: val_loss did not improve from 0.03025
Epoch 475/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0438
2/2 [==============================] - 2s 1s/step - loss: 0.0418 - val_loss: 0.0374

Epoch 00475: val_loss did not improve from 0.03025
Epoch 476/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0498
2/2 [==============================] - 2s 1s/step - loss: 0.0439 - val_loss: 0.0404

Epoch 00476: val_loss did not improve from 0.03025
Epoch 477/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0446
2/2 [==============================] - 2s 1s/step - loss: 0.0389 - val_loss: 0.0433

Epoch 00477: val_loss did not improve from 0.03025
Epoch 478/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0430
2/2 [==============================] - 2s 1s/step - loss: 0.0382 - val_loss: 0.0419

Epoch 00478: val_loss did not improve from 0.03025
Epoch 479/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0398
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0353

Epoch 00479: val_loss did not improve from 0.03025
Epoch 480/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0403
2/2 [==============================] - 2s 1s/step - loss: 0.0443 - val_loss: 0.0398

Epoch 00480: val_loss did not improve from 0.03025
Epoch 481/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0388
2/2 [==============================] - 2s 1s/step - loss: 0.0389 - val_loss: 0.0385

Epoch 00481: val_loss did not improve from 0.03025
Epoch 482/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0410
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0372

Epoch 00482: val_loss did not improve from 0.03025
Epoch 483/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0453
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0392

Epoch 00483: val_loss did not improve from 0.03025
Epoch 484/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0350
2/2 [==============================] - 2s 1s/step - loss: 0.0336 - val_loss: 0.0452

Epoch 00484: val_loss did not improve from 0.03025
Epoch 485/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0389
2/2 [==============================] - 2s 1s/step - loss: 0.0410 - val_loss: 0.0415

Epoch 00485: val_loss did not improve from 0.03025
Epoch 486/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0494
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0318

Epoch 00486: val_loss did not improve from 0.03025
Epoch 487/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0391
2/2 [==============================] - 2s 1s/step - loss: 0.0374 - val_loss: 0.0395

Epoch 00487: val_loss did not improve from 0.03025
Epoch 488/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0324
2/2 [==============================] - 2s 1s/step - loss: 0.0363 - val_loss: 0.0347

Epoch 00488: val_loss did not improve from 0.03025
Epoch 489/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0387
2/2 [==============================] - 2s 1s/step - loss: 0.0353 - val_loss: 0.0431

Epoch 00489: val_loss did not improve from 0.03025
Epoch 490/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0417 - val_loss: 0.0402

Epoch 00490: val_loss did not improve from 0.03025
Epoch 491/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0439
2/2 [==============================] - 2s 1s/step - loss: 0.0405 - val_loss: 0.0404

Epoch 00491: val_loss did not improve from 0.03025
Epoch 492/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0418
2/2 [==============================] - 2s 1s/step - loss: 0.0395 - val_loss: 0.0416

Epoch 00492: val_loss did not improve from 0.03025
Epoch 493/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0453
2/2 [==============================] - 2s 1s/step - loss: 0.0438 - val_loss: 0.0422

Epoch 00493: val_loss did not improve from 0.03025
Epoch 494/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0365
2/2 [==============================] - 2s 1s/step - loss: 0.0345 - val_loss: 0.0379

Epoch 00494: val_loss did not improve from 0.03025
Epoch 495/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0419
2/2 [==============================] - 2s 1s/step - loss: 0.0400 - val_loss: 0.0390

Epoch 00495: val_loss did not improve from 0.03025
Epoch 496/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0390
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0343

Epoch 00496: val_loss did not improve from 0.03025
Epoch 497/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0384
2/2 [==============================] - 2s 1s/step - loss: 0.0390 - val_loss: 0.0422

Epoch 00497: val_loss did not improve from 0.03025
Epoch 498/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0417
2/2 [==============================] - 2s 1s/step - loss: 0.0420 - val_loss: 0.0308

Epoch 00498: val_loss did not improve from 0.03025
Epoch 499/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0369
2/2 [==============================] - 2s 1s/step - loss: 0.0410 - val_loss: 0.0450

Epoch 00499: val_loss did not improve from 0.03025
Epoch 500/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0440
2/2 [==============================] - 2s 1s/step - loss: 0.0433 - val_loss: 0.0468

Epoch 00500: val_loss did not improve from 0.03025
Epoch 501/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0386
2/2 [==============================] - 2s 1s/step - loss: 0.0404 - val_loss: 0.0433

Epoch 00501: val_loss did not improve from 0.03025
Epoch 502/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0371
2/2 [==============================] - 2s 1s/step - loss: 0.0390 - val_loss: 0.0343

Epoch 00502: val_loss did not improve from 0.03025
Epoch 503/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0400
2/2 [==============================] - 2s 1s/step - loss: 0.0429 - val_loss: 0.0410

Epoch 00503: val_loss did not improve from 0.03025
Epoch 504/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0422
2/2 [==============================] - 2s 1s/step - loss: 0.0404 - val_loss: 0.0376

Epoch 00504: val_loss did not improve from 0.03025
Epoch 505/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0399
2/2 [==============================] - 2s 1s/step - loss: 0.0405 - val_loss: 0.0450

Epoch 00505: val_loss did not improve from 0.03025
Epoch 506/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0357
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0451

Epoch 00506: val_loss did not improve from 0.03025
Epoch 507/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0398
2/2 [==============================] - 2s 1s/step - loss: 0.0441 - val_loss: 0.0415

Epoch 00507: val_loss did not improve from 0.03025
Epoch 508/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0341
2/2 [==============================] - 2s 1s/step - loss: 0.0376 - val_loss: 0.0414

Epoch 00508: val_loss did not improve from 0.03025
Epoch 509/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0405
2/2 [==============================] - 2s 1s/step - loss: 0.0430 - val_loss: 0.0384

Epoch 00509: val_loss did not improve from 0.03025
Epoch 510/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0311
2/2 [==============================] - 2s 1s/step - loss: 0.0380 - val_loss: 0.0371

Epoch 00510: val_loss did not improve from 0.03025
Epoch 511/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0416
2/2 [==============================] - 2s 1s/step - loss: 0.0434 - val_loss: 0.0378

Epoch 00511: val_loss did not improve from 0.03025
Epoch 512/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0436
2/2 [==============================] - 2s 1s/step - loss: 0.0432 - val_loss: 0.0437

Epoch 00512: val_loss did not improve from 0.03025
Epoch 513/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0451
2/2 [==============================] - 2s 1s/step - loss: 0.0473 - val_loss: 0.0394

Epoch 00513: val_loss did not improve from 0.03025
Epoch 514/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0269
2/2 [==============================] - 2s 1s/step - loss: 0.0342 - val_loss: 0.0389

Epoch 00514: val_loss did not improve from 0.03025
Epoch 515/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0412
2/2 [==============================] - 2s 1s/step - loss: 0.0374 - val_loss: 0.0345

Epoch 00515: val_loss did not improve from 0.03025
Epoch 516/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0422
2/2 [==============================] - 2s 1s/step - loss: 0.0419 - val_loss: 0.0376

Epoch 00516: val_loss did not improve from 0.03025
Epoch 517/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0395
2/2 [==============================] - 2s 1s/step - loss: 0.0319 - val_loss: 0.0419

Epoch 00517: val_loss did not improve from 0.03025
Epoch 518/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0439
2/2 [==============================] - 2s 1s/step - loss: 0.0345 - val_loss: 0.0364

Epoch 00518: val_loss did not improve from 0.03025
Epoch 519/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0467
2/2 [==============================] - 2s 1s/step - loss: 0.0435 - val_loss: 0.0394

Epoch 00519: val_loss did not improve from 0.03025
Epoch 520/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0365
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0426

Epoch 00520: val_loss did not improve from 0.03025
Epoch 521/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0333
2/2 [==============================] - 2s 1s/step - loss: 0.0375 - val_loss: 0.0431

Epoch 00521: val_loss did not improve from 0.03025
Epoch 522/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0440
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0375

Epoch 00522: val_loss did not improve from 0.03025
Epoch 523/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0421
2/2 [==============================] - 2s 1s/step - loss: 0.0408 - val_loss: 0.0384

Epoch 00523: val_loss did not improve from 0.03025
Epoch 524/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0400
2/2 [==============================] - 2s 1s/step - loss: 0.0374 - val_loss: 0.0389

Epoch 00524: val_loss did not improve from 0.03025
Epoch 525/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0330
2/2 [==============================] - 3s 1s/step - loss: 0.0381 - val_loss: 0.0411

Epoch 00525: val_loss did not improve from 0.03025
Epoch 526/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0449
2/2 [==============================] - 2s 1s/step - loss: 0.0362 - val_loss: 0.0403

Epoch 00526: val_loss did not improve from 0.03025
Epoch 527/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0319
2/2 [==============================] - 2s 1s/step - loss: 0.0326 - val_loss: 0.0469

Epoch 00527: val_loss did not improve from 0.03025
Epoch 528/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0426
2/2 [==============================] - 2s 1s/step - loss: 0.0422 - val_loss: 0.0424

Epoch 00528: val_loss did not improve from 0.03025
Epoch 529/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0372
2/2 [==============================] - 2s 1s/step - loss: 0.0388 - val_loss: 0.0380

Epoch 00529: val_loss did not improve from 0.03025
Epoch 530/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0432
2/2 [==============================] - 2s 1s/step - loss: 0.0408 - val_loss: 0.0421

Epoch 00530: val_loss did not improve from 0.03025
Epoch 531/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0457
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0466

Epoch 00531: val_loss did not improve from 0.03025
Epoch 532/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0385
2/2 [==============================] - 2s 1s/step - loss: 0.0360 - val_loss: 0.0427

Epoch 00532: val_loss did not improve from 0.03025
Epoch 533/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0346
2/2 [==============================] - 2s 1s/step - loss: 0.0341 - val_loss: 0.0450

Epoch 00533: val_loss did not improve from 0.03025
Epoch 534/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0395
2/2 [==============================] - 3s 1s/step - loss: 0.0388 - val_loss: 0.0443

Epoch 00534: val_loss did not improve from 0.03025
Epoch 535/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0389
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0431

Epoch 00535: val_loss did not improve from 0.03025
Epoch 536/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0370
2/2 [==============================] - 2s 1s/step - loss: 0.0354 - val_loss: 0.0390

Epoch 00536: val_loss did not improve from 0.03025
Epoch 537/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0375
2/2 [==============================] - 2s 1s/step - loss: 0.0348 - val_loss: 0.0399

Epoch 00537: val_loss did not improve from 0.03025
Epoch 538/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0446
2/2 [==============================] - 2s 1s/step - loss: 0.0430 - val_loss: 0.0423

Epoch 00538: val_loss did not improve from 0.03025
Epoch 539/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0381
2/2 [==============================] - 2s 1s/step - loss: 0.0374 - val_loss: 0.0434

Epoch 00539: val_loss did not improve from 0.03025
Epoch 540/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0369
2/2 [==============================] - 3s 1s/step - loss: 0.0370 - val_loss: 0.0392

Epoch 00540: val_loss did not improve from 0.03025
Epoch 541/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0507
2/2 [==============================] - 2s 1s/step - loss: 0.0433 - val_loss: 0.0378

Epoch 00541: val_loss did not improve from 0.03025
Epoch 542/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0373
2/2 [==============================] - 2s 1s/step - loss: 0.0400 - val_loss: 0.0337

Epoch 00542: val_loss did not improve from 0.03025
Epoch 543/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0372
2/2 [==============================] - 2s 1s/step - loss: 0.0378 - val_loss: 0.0420

Epoch 00543: val_loss did not improve from 0.03025
Epoch 544/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0451
2/2 [==============================] - 2s 1s/step - loss: 0.0429 - val_loss: 0.0398

Epoch 00544: val_loss did not improve from 0.03025
Epoch 545/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0301
2/2 [==============================] - 2s 1s/step - loss: 0.0360 - val_loss: 0.0386

Epoch 00545: val_loss did not improve from 0.03025
Epoch 546/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0430
2/2 [==============================] - 3s 1s/step - loss: 0.0442 - val_loss: 0.0425

Epoch 00546: val_loss did not improve from 0.03025
Epoch 547/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0388
2/2 [==============================] - 2s 1s/step - loss: 0.0370 - val_loss: 0.0446

Epoch 00547: val_loss did not improve from 0.03025
Epoch 548/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0310
2/2 [==============================] - 2s 1s/step - loss: 0.0362 - val_loss: 0.0367

Epoch 00548: val_loss did not improve from 0.03025
Epoch 549/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0400
2/2 [==============================] - 2s 1s/step - loss: 0.0384 - val_loss: 0.0327

Epoch 00549: val_loss did not improve from 0.03025
Epoch 550/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0372
2/2 [==============================] - 2s 1s/step - loss: 0.0401 - val_loss: 0.0422

Epoch 00550: val_loss did not improve from 0.03025
Epoch 551/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0356
2/2 [==============================] - 2s 1s/step - loss: 0.0354 - val_loss: 0.0296

Epoch 00551: val_loss improved from 0.03025 to 0.02957, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 552/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0365
2/2 [==============================] - 2s 1s/step - loss: 0.0340 - val_loss: 0.0440

Epoch 00552: val_loss did not improve from 0.02957
Epoch 553/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0467
2/2 [==============================] - 2s 1s/step - loss: 0.0448 - val_loss: 0.0387

Epoch 00553: val_loss did not improve from 0.02957
Epoch 554/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0396
2/2 [==============================] - 2s 1s/step - loss: 0.0390 - val_loss: 0.0448

Epoch 00554: val_loss did not improve from 0.02957
Epoch 555/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0399
2/2 [==============================] - 2s 1s/step - loss: 0.0427 - val_loss: 0.0369

Epoch 00555: val_loss did not improve from 0.02957
Epoch 556/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0421
2/2 [==============================] - 2s 1s/step - loss: 0.0357 - val_loss: 0.0449

Epoch 00556: val_loss did not improve from 0.02957
Epoch 557/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0368
2/2 [==============================] - 2s 1s/step - loss: 0.0376 - val_loss: 0.0470

Epoch 00557: val_loss did not improve from 0.02957
Epoch 558/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0398
2/2 [==============================] - 2s 1s/step - loss: 0.0388 - val_loss: 0.0433

Epoch 00558: val_loss did not improve from 0.02957
Epoch 559/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0342
2/2 [==============================] - 2s 1s/step - loss: 0.0352 - val_loss: 0.0375

Epoch 00559: val_loss did not improve from 0.02957
Epoch 560/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0376
2/2 [==============================] - 2s 1s/step - loss: 0.0382 - val_loss: 0.0352

Epoch 00560: val_loss did not improve from 0.02957
Epoch 561/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0357
2/2 [==============================] - 2s 1s/step - loss: 0.0350 - val_loss: 0.0383

Epoch 00561: val_loss did not improve from 0.02957
Epoch 562/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0388
2/2 [==============================] - 2s 1s/step - loss: 0.0408 - val_loss: 0.0402

Epoch 00562: val_loss did not improve from 0.02957
Epoch 563/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0399
2/2 [==============================] - 2s 1s/step - loss: 0.0373 - val_loss: 0.0376

Epoch 00563: val_loss did not improve from 0.02957
Epoch 564/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0431
2/2 [==============================] - 3s 1s/step - loss: 0.0424 - val_loss: 0.0364

Epoch 00564: val_loss did not improve from 0.02957
Epoch 565/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0460
2/2 [==============================] - 2s 1s/step - loss: 0.0430 - val_loss: 0.0434

Epoch 00565: val_loss did not improve from 0.02957
Epoch 566/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0342
2/2 [==============================] - 2s 1s/step - loss: 0.0373 - val_loss: 0.0356

Epoch 00566: val_loss did not improve from 0.02957
Epoch 567/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0349
2/2 [==============================] - 3s 1s/step - loss: 0.0360 - val_loss: 0.0418

Epoch 00567: val_loss did not improve from 0.02957
Epoch 568/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0422
2/2 [==============================] - 2s 1s/step - loss: 0.0430 - val_loss: 0.0434

Epoch 00568: val_loss did not improve from 0.02957
Epoch 569/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0441
2/2 [==============================] - 2s 1s/step - loss: 0.0414 - val_loss: 0.0407

Epoch 00569: val_loss did not improve from 0.02957
Epoch 570/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0499
2/2 [==============================] - 2s 1s/step - loss: 0.0497 - val_loss: 0.0428

Epoch 00570: val_loss did not improve from 0.02957
Epoch 571/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0384
2/2 [==============================] - 2s 1s/step - loss: 0.0358 - val_loss: 0.0406

Epoch 00571: val_loss did not improve from 0.02957
Epoch 572/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0354
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0351

Epoch 00572: val_loss did not improve from 0.02957
Epoch 573/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0353
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0382

Epoch 00573: val_loss did not improve from 0.02957
Epoch 574/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0357
2/2 [==============================] - 2s 1s/step - loss: 0.0345 - val_loss: 0.0432

Epoch 00574: val_loss did not improve from 0.02957
Epoch 575/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0444
2/2 [==============================] - 2s 1s/step - loss: 0.0422 - val_loss: 0.0389

Epoch 00575: val_loss did not improve from 0.02957
Epoch 576/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0392
2/2 [==============================] - 3s 1s/step - loss: 0.0428 - val_loss: 0.0388

Epoch 00576: val_loss did not improve from 0.02957
Epoch 577/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0399
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0399

Epoch 00577: val_loss did not improve from 0.02957
Epoch 578/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0382
2/2 [==============================] - 2s 1s/step - loss: 0.0355 - val_loss: 0.0369

Epoch 00578: val_loss did not improve from 0.02957
Epoch 579/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0346
2/2 [==============================] - 2s 1s/step - loss: 0.0370 - val_loss: 0.0440

Epoch 00579: val_loss did not improve from 0.02957
Epoch 580/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0382
2/2 [==============================] - 2s 1s/step - loss: 0.0408 - val_loss: 0.0360

Epoch 00580: val_loss did not improve from 0.02957
Epoch 581/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0443
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0427

Epoch 00581: val_loss did not improve from 0.02957
Epoch 582/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0447
2/2 [==============================] - 3s 1s/step - loss: 0.0470 - val_loss: 0.0377

Epoch 00582: val_loss did not improve from 0.02957
Epoch 583/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0445
2/2 [==============================] - 2s 1s/step - loss: 0.0410 - val_loss: 0.0452

Epoch 00583: val_loss did not improve from 0.02957
Epoch 584/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0434
2/2 [==============================] - 2s 1s/step - loss: 0.0395 - val_loss: 0.0385

Epoch 00584: val_loss did not improve from 0.02957
Epoch 585/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0363
2/2 [==============================] - 2s 1s/step - loss: 0.0423 - val_loss: 0.0323

Epoch 00585: val_loss did not improve from 0.02957
Epoch 586/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0404
2/2 [==============================] - 3s 1s/step - loss: 0.0449 - val_loss: 0.0406

Epoch 00586: val_loss did not improve from 0.02957
Epoch 587/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0326
2/2 [==============================] - 3s 1s/step - loss: 0.0330 - val_loss: 0.0376

Epoch 00587: val_loss did not improve from 0.02957
Epoch 588/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0389
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0417

Epoch 00588: val_loss did not improve from 0.02957
Epoch 589/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0423
2/2 [==============================] - 2s 1s/step - loss: 0.0369 - val_loss: 0.0432

Epoch 00589: val_loss did not improve from 0.02957
Epoch 590/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0344
2/2 [==============================] - 2s 1s/step - loss: 0.0367 - val_loss: 0.0420

Epoch 00590: val_loss did not improve from 0.02957
Epoch 591/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0408
2/2 [==============================] - 3s 1s/step - loss: 0.0390 - val_loss: 0.0318

Epoch 00591: val_loss did not improve from 0.02957
Epoch 592/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0381
2/2 [==============================] - 2s 1s/step - loss: 0.0458 - val_loss: 0.0407

Epoch 00592: val_loss did not improve from 0.02957
Epoch 593/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0453
2/2 [==============================] - 2s 1s/step - loss: 0.0423 - val_loss: 0.0428

Epoch 00593: val_loss did not improve from 0.02957
Epoch 594/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0351
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0399

Epoch 00594: val_loss did not improve from 0.02957
Epoch 595/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0343
2/2 [==============================] - 2s 1s/step - loss: 0.0385 - val_loss: 0.0372

Epoch 00595: val_loss did not improve from 0.02957
Epoch 596/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0424
2/2 [==============================] - 2s 1s/step - loss: 0.0428 - val_loss: 0.0457

Epoch 00596: val_loss did not improve from 0.02957
Epoch 597/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0362
2/2 [==============================] - 3s 1s/step - loss: 0.0393 - val_loss: 0.0448

Epoch 00597: val_loss did not improve from 0.02957
Epoch 598/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0361
2/2 [==============================] - 2s 1s/step - loss: 0.0353 - val_loss: 0.0381

Epoch 00598: val_loss did not improve from 0.02957
Epoch 599/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0447
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0434

Epoch 00599: val_loss did not improve from 0.02957
Epoch 600/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0458
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0409

Epoch 00600: val_loss did not improve from 0.02957
Epoch 601/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0450
2/2 [==============================] - 2s 1s/step - loss: 0.0438 - val_loss: 0.0337

Epoch 00601: val_loss did not improve from 0.02957
Epoch 602/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0428
2/2 [==============================] - 2s 1s/step - loss: 0.0406 - val_loss: 0.0392

Epoch 00602: val_loss did not improve from 0.02957
Epoch 603/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0399
2/2 [==============================] - 2s 1s/step - loss: 0.0411 - val_loss: 0.0403

Epoch 00603: val_loss did not improve from 0.02957
Epoch 604/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0487
2/2 [==============================] - 3s 1s/step - loss: 0.0433 - val_loss: 0.0415

Epoch 00604: val_loss did not improve from 0.02957
Epoch 605/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0407
2/2 [==============================] - 2s 1s/step - loss: 0.0368 - val_loss: 0.0473

Epoch 00605: val_loss did not improve from 0.02957
Epoch 606/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0445
2/2 [==============================] - 2s 1s/step - loss: 0.0444 - val_loss: 0.0396

Epoch 00606: val_loss did not improve from 0.02957
Epoch 607/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0321
2/2 [==============================] - 2s 1s/step - loss: 0.0362 - val_loss: 0.0427

Epoch 00607: val_loss did not improve from 0.02957
Epoch 608/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0400
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0444

Epoch 00608: val_loss did not improve from 0.02957
Epoch 609/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0480
2/2 [==============================] - 2s 1s/step - loss: 0.0388 - val_loss: 0.0393

Epoch 00609: val_loss did not improve from 0.02957
Epoch 610/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0389
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0420

Epoch 00610: val_loss did not improve from 0.02957
Epoch 611/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0447
2/2 [==============================] - 3s 1s/step - loss: 0.0413 - val_loss: 0.0460

Epoch 00611: val_loss did not improve from 0.02957
Epoch 612/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0372
2/2 [==============================] - 2s 1s/step - loss: 0.0420 - val_loss: 0.0431

Epoch 00612: val_loss did not improve from 0.02957
Epoch 613/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0399
2/2 [==============================] - 2s 1s/step - loss: 0.0400 - val_loss: 0.0327

Epoch 00613: val_loss did not improve from 0.02957
Epoch 614/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0382
2/2 [==============================] - 2s 1s/step - loss: 0.0362 - val_loss: 0.0366

Epoch 00614: val_loss did not improve from 0.02957
Epoch 615/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0434 - val_loss: 0.0359

Epoch 00615: val_loss did not improve from 0.02957
Epoch 616/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0468
2/2 [==============================] - 2s 1s/step - loss: 0.0423 - val_loss: 0.0408

Epoch 00616: val_loss did not improve from 0.02957
Epoch 617/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0460
2/2 [==============================] - 2s 1s/step - loss: 0.0406 - val_loss: 0.0407

Epoch 00617: val_loss did not improve from 0.02957
Epoch 618/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0473
2/2 [==============================] - 2s 1s/step - loss: 0.0409 - val_loss: 0.0432

Epoch 00618: val_loss did not improve from 0.02957
Epoch 619/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0375
2/2 [==============================] - 2s 1s/step - loss: 0.0356 - val_loss: 0.0380

Epoch 00619: val_loss did not improve from 0.02957
Epoch 620/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0346
2/2 [==============================] - 2s 1s/step - loss: 0.0306 - val_loss: 0.0433

Epoch 00620: val_loss did not improve from 0.02957
Epoch 621/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0466
2/2 [==============================] - 3s 1s/step - loss: 0.0454 - val_loss: 0.0397

Epoch 00621: val_loss did not improve from 0.02957
Epoch 622/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0389
2/2 [==============================] - 2s 1s/step - loss: 0.0373 - val_loss: 0.0377

Epoch 00622: val_loss did not improve from 0.02957
Epoch 623/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0387 - val_loss: 0.0331

Epoch 00623: val_loss did not improve from 0.02957
Epoch 624/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0424
2/2 [==============================] - 2s 1s/step - loss: 0.0411 - val_loss: 0.0418

Epoch 00624: val_loss did not improve from 0.02957
Epoch 625/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0423
2/2 [==============================] - 2s 1s/step - loss: 0.0434 - val_loss: 0.0358

Epoch 00625: val_loss did not improve from 0.02957
Epoch 626/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0367
2/2 [==============================] - 2s 1s/step - loss: 0.0385 - val_loss: 0.0417

Epoch 00626: val_loss did not improve from 0.02957
Epoch 627/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0436
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0419

Epoch 00627: val_loss did not improve from 0.02957
Epoch 628/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0354
2/2 [==============================] - 2s 1s/step - loss: 0.0369 - val_loss: 0.0405

Epoch 00628: val_loss did not improve from 0.02957
Epoch 629/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0483
2/2 [==============================] - 2s 1s/step - loss: 0.0436 - val_loss: 0.0417

Epoch 00629: val_loss did not improve from 0.02957
Epoch 630/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0400
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0371

Epoch 00630: val_loss did not improve from 0.02957
Epoch 631/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0409
2/2 [==============================] - 3s 1s/step - loss: 0.0384 - val_loss: 0.0387

Epoch 00631: val_loss did not improve from 0.02957
Epoch 632/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0430
2/2 [==============================] - 2s 1s/step - loss: 0.0389 - val_loss: 0.0417

Epoch 00632: val_loss did not improve from 0.02957
Epoch 633/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0417
2/2 [==============================] - 3s 1s/step - loss: 0.0359 - val_loss: 0.0358

Epoch 00633: val_loss did not improve from 0.02957
Epoch 634/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0462
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0367

Epoch 00634: val_loss did not improve from 0.02957
Epoch 635/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0469
2/2 [==============================] - 2s 1s/step - loss: 0.0414 - val_loss: 0.0429

Epoch 00635: val_loss did not improve from 0.02957
Epoch 636/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0426
2/2 [==============================] - 3s 1s/step - loss: 0.0377 - val_loss: 0.0373

Epoch 00636: val_loss did not improve from 0.02957
Epoch 637/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0375
2/2 [==============================] - 2s 1s/step - loss: 0.0421 - val_loss: 0.0403

Epoch 00637: val_loss did not improve from 0.02957
Epoch 638/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0415
2/2 [==============================] - 2s 1s/step - loss: 0.0426 - val_loss: 0.0390

Epoch 00638: val_loss did not improve from 0.02957
Epoch 639/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0436
2/2 [==============================] - 2s 1s/step - loss: 0.0434 - val_loss: 0.0385

Epoch 00639: val_loss did not improve from 0.02957
Epoch 640/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0470
2/2 [==============================] - 2s 1s/step - loss: 0.0424 - val_loss: 0.0329

Epoch 00640: val_loss did not improve from 0.02957
Epoch 641/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0454
2/2 [==============================] - 2s 1s/step - loss: 0.0439 - val_loss: 0.0313

Epoch 00641: val_loss did not improve from 0.02957
Epoch 642/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0396
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0383

Epoch 00642: val_loss did not improve from 0.02957
Epoch 643/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0323
2/2 [==============================] - 2s 1s/step - loss: 0.0338 - val_loss: 0.0360

Epoch 00643: val_loss did not improve from 0.02957
Epoch 644/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0357
2/2 [==============================] - 2s 1s/step - loss: 0.0386 - val_loss: 0.0424

Epoch 00644: val_loss did not improve from 0.02957
Epoch 645/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0428
2/2 [==============================] - 2s 1s/step - loss: 0.0422 - val_loss: 0.0389

Epoch 00645: val_loss did not improve from 0.02957
Epoch 646/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0384
2/2 [==============================] - 2s 1s/step - loss: 0.0380 - val_loss: 0.0458

Epoch 00646: val_loss did not improve from 0.02957
Epoch 647/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0396
2/2 [==============================] - 3s 1s/step - loss: 0.0367 - val_loss: 0.0397

Epoch 00647: val_loss did not improve from 0.02957
Epoch 648/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0363
2/2 [==============================] - 2s 1s/step - loss: 0.0391 - val_loss: 0.0367

Epoch 00648: val_loss did not improve from 0.02957
Epoch 649/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0464
2/2 [==============================] - 2s 1s/step - loss: 0.0433 - val_loss: 0.0410

Epoch 00649: val_loss did not improve from 0.02957
Epoch 650/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0409
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0375

Epoch 00650: val_loss did not improve from 0.02957
Epoch 651/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0381
2/2 [==============================] - 2s 1s/step - loss: 0.0430 - val_loss: 0.0409

Epoch 00651: val_loss did not improve from 0.02957
Epoch 652/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0431
2/2 [==============================] - 2s 1s/step - loss: 0.0450 - val_loss: 0.0433

Epoch 00652: val_loss did not improve from 0.02957
Epoch 653/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0411
2/2 [==============================] - 2s 1s/step - loss: 0.0433 - val_loss: 0.0403

Epoch 00653: val_loss did not improve from 0.02957
Epoch 654/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0307
2/2 [==============================] - 2s 1s/step - loss: 0.0358 - val_loss: 0.0418

Epoch 00654: val_loss did not improve from 0.02957
Epoch 655/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0414
2/2 [==============================] - 3s 1s/step - loss: 0.0401 - val_loss: 0.0363

Epoch 00655: val_loss did not improve from 0.02957
Epoch 656/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0369
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0398

Epoch 00656: val_loss did not improve from 0.02957
Epoch 657/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0311
2/2 [==============================] - 2s 1s/step - loss: 0.0357 - val_loss: 0.0390

Epoch 00657: val_loss did not improve from 0.02957
Epoch 658/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0452
2/2 [==============================] - 2s 1s/step - loss: 0.0423 - val_loss: 0.0450

Epoch 00658: val_loss did not improve from 0.02957
Epoch 659/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0441
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0398

Epoch 00659: val_loss did not improve from 0.02957
Epoch 660/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0475
2/2 [==============================] - 2s 1s/step - loss: 0.0409 - val_loss: 0.0399

Epoch 00660: val_loss did not improve from 0.02957
Epoch 661/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0364
2/2 [==============================] - 2s 1s/step - loss: 0.0389 - val_loss: 0.0426

Epoch 00661: val_loss did not improve from 0.02957
Epoch 662/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0436
2/2 [==============================] - 2s 1s/step - loss: 0.0417 - val_loss: 0.0474

Epoch 00662: val_loss did not improve from 0.02957
Epoch 663/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0439
2/2 [==============================] - 2s 1s/step - loss: 0.0465 - val_loss: 0.0395

Epoch 00663: val_loss did not improve from 0.02957
Epoch 664/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0387
2/2 [==============================] - 2s 1s/step - loss: 0.0387 - val_loss: 0.0402

Epoch 00664: val_loss did not improve from 0.02957
Epoch 665/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0404
2/2 [==============================] - 2s 1s/step - loss: 0.0387 - val_loss: 0.0424

Epoch 00665: val_loss did not improve from 0.02957
Epoch 666/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0419
2/2 [==============================] - 2s 1s/step - loss: 0.0392 - val_loss: 0.0403

Epoch 00666: val_loss did not improve from 0.02957
Epoch 667/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0404
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0406

Epoch 00667: val_loss did not improve from 0.02957
Epoch 668/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0431
2/2 [==============================] - 2s 1s/step - loss: 0.0429 - val_loss: 0.0370

Epoch 00668: val_loss did not improve from 0.02957
Epoch 669/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0388
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0434

Epoch 00669: val_loss did not improve from 0.02957
Epoch 670/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0449
2/2 [==============================] - 2s 1s/step - loss: 0.0421 - val_loss: 0.0390

Epoch 00670: val_loss did not improve from 0.02957
Epoch 671/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0385
2/2 [==============================] - 3s 1s/step - loss: 0.0408 - val_loss: 0.0415

Epoch 00671: val_loss did not improve from 0.02957
Epoch 672/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0408
2/2 [==============================] - 2s 1s/step - loss: 0.0402 - val_loss: 0.0419

Epoch 00672: val_loss did not improve from 0.02957
Epoch 673/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0348
2/2 [==============================] - 2s 1s/step - loss: 0.0371 - val_loss: 0.0384

Epoch 00673: val_loss did not improve from 0.02957
Epoch 674/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0385
2/2 [==============================] - 2s 1s/step - loss: 0.0361 - val_loss: 0.0392

Epoch 00674: val_loss did not improve from 0.02957
Epoch 675/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0390
2/2 [==============================] - 2s 1s/step - loss: 0.0393 - val_loss: 0.0415

Epoch 00675: val_loss did not improve from 0.02957
Epoch 676/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0421
2/2 [==============================] - 2s 1s/step - loss: 0.0424 - val_loss: 0.0429

Epoch 00676: val_loss did not improve from 0.02957
Epoch 677/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0418
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0382

Epoch 00677: val_loss did not improve from 0.02957
Epoch 678/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0442
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0366

Epoch 00678: val_loss did not improve from 0.02957
Epoch 679/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0340
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0377

Epoch 00679: val_loss did not improve from 0.02957
Epoch 680/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0387
2/2 [==============================] - 2s 1s/step - loss: 0.0406 - val_loss: 0.0401

Epoch 00680: val_loss did not improve from 0.02957
Epoch 681/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0414
2/2 [==============================] - 2s 1s/step - loss: 0.0437 - val_loss: 0.0452

Epoch 00681: val_loss did not improve from 0.02957
Epoch 682/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0411
2/2 [==============================] - 2s 1s/step - loss: 0.0401 - val_loss: 0.0380

Epoch 00682: val_loss did not improve from 0.02957
Epoch 683/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0405
2/2 [==============================] - 2s 1s/step - loss: 0.0405 - val_loss: 0.0357

Epoch 00683: val_loss did not improve from 0.02957
Epoch 684/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0352
2/2 [==============================] - 2s 1s/step - loss: 0.0393 - val_loss: 0.0440

Epoch 00684: val_loss did not improve from 0.02957
Epoch 685/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0332
2/2 [==============================] - 2s 1s/step - loss: 0.0333 - val_loss: 0.0452

Epoch 00685: val_loss did not improve from 0.02957
Epoch 686/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0354
2/2 [==============================] - 2s 1s/step - loss: 0.0354 - val_loss: 0.0414

Epoch 00686: val_loss did not improve from 0.02957
Epoch 687/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0401 - val_loss: 0.0416

Epoch 00687: val_loss did not improve from 0.02957
Epoch 688/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0428
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0397

Epoch 00688: val_loss did not improve from 0.02957
Epoch 689/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0470
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0349

Epoch 00689: val_loss did not improve from 0.02957
Epoch 690/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0350
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0394

Epoch 00690: val_loss did not improve from 0.02957
Epoch 691/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0451
2/2 [==============================] - 2s 1s/step - loss: 0.0448 - val_loss: 0.0461

Epoch 00691: val_loss did not improve from 0.02957
Epoch 692/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0260
2/2 [==============================] - 2s 1s/step - loss: 0.0350 - val_loss: 0.0400

Epoch 00692: val_loss did not improve from 0.02957
Epoch 693/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0362
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0413

Epoch 00693: val_loss did not improve from 0.02957
Epoch 694/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0348
2/2 [==============================] - 2s 1s/step - loss: 0.0392 - val_loss: 0.0388

Epoch 00694: val_loss did not improve from 0.02957
Epoch 695/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0429
2/2 [==============================] - 2s 1s/step - loss: 0.0423 - val_loss: 0.0468

Epoch 00695: val_loss did not improve from 0.02957
Epoch 696/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0449 - val_loss: 0.0401

Epoch 00696: val_loss did not improve from 0.02957
Epoch 697/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0314
2/2 [==============================] - 2s 1s/step - loss: 0.0374 - val_loss: 0.0373

Epoch 00697: val_loss did not improve from 0.02957
Epoch 698/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0415
2/2 [==============================] - 2s 1s/step - loss: 0.0409 - val_loss: 0.0368

Epoch 00698: val_loss did not improve from 0.02957
Epoch 699/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0393
2/2 [==============================] - 2s 1s/step - loss: 0.0429 - val_loss: 0.0419

Epoch 00699: val_loss did not improve from 0.02957
Epoch 700/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0432
2/2 [==============================] - 2s 1s/step - loss: 0.0422 - val_loss: 0.0442

Epoch 00700: val_loss did not improve from 0.02957
Epoch 701/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0410
2/2 [==============================] - 2s 1s/step - loss: 0.0444 - val_loss: 0.0326

Epoch 00701: val_loss did not improve from 0.02957
Epoch 702/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0453
2/2 [==============================] - 2s 1s/step - loss: 0.0385 - val_loss: 0.0434

Epoch 00702: val_loss did not improve from 0.02957
Epoch 703/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0302
2/2 [==============================] - 2s 1s/step - loss: 0.0306 - val_loss: 0.0397

Epoch 00703: val_loss did not improve from 0.02957
Epoch 704/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0383
2/2 [==============================] - 2s 1s/step - loss: 0.0383 - val_loss: 0.0423

Epoch 00704: val_loss did not improve from 0.02957
Epoch 705/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0460
2/2 [==============================] - 2s 1s/step - loss: 0.0452 - val_loss: 0.0421

Epoch 00705: val_loss did not improve from 0.02957
Epoch 706/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0426

Epoch 00706: val_loss did not improve from 0.02957
Epoch 707/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0406
2/2 [==============================] - 2s 1s/step - loss: 0.0377 - val_loss: 0.0491

Epoch 00707: val_loss did not improve from 0.02957
Epoch 708/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0385
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0430

Epoch 00708: val_loss did not improve from 0.02957
Epoch 709/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0404
2/2 [==============================] - 2s 1s/step - loss: 0.0366 - val_loss: 0.0389

Epoch 00709: val_loss did not improve from 0.02957
Epoch 710/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0418
2/2 [==============================] - 2s 1s/step - loss: 0.0400 - val_loss: 0.0393

Epoch 00710: val_loss did not improve from 0.02957
Epoch 711/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0397
2/2 [==============================] - 2s 1s/step - loss: 0.0420 - val_loss: 0.0392

Epoch 00711: val_loss did not improve from 0.02957
Epoch 712/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0360
2/2 [==============================] - 2s 1s/step - loss: 0.0358 - val_loss: 0.0408

Epoch 00712: val_loss did not improve from 0.02957
Epoch 713/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0442
2/2 [==============================] - 2s 1s/step - loss: 0.0420 - val_loss: 0.0414

Epoch 00713: val_loss did not improve from 0.02957
Epoch 714/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0421
2/2 [==============================] - 2s 1s/step - loss: 0.0420 - val_loss: 0.0425

Epoch 00714: val_loss did not improve from 0.02957
Epoch 715/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0402
2/2 [==============================] - 2s 1s/step - loss: 0.0422 - val_loss: 0.0405

Epoch 00715: val_loss did not improve from 0.02957
Epoch 716/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0398
2/2 [==============================] - 2s 1s/step - loss: 0.0380 - val_loss: 0.0453

Epoch 00716: val_loss did not improve from 0.02957
Epoch 717/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0495
2/2 [==============================] - 2s 1s/step - loss: 0.0448 - val_loss: 0.0411

Epoch 00717: val_loss did not improve from 0.02957
Epoch 718/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0392
2/2 [==============================] - 2s 1s/step - loss: 0.0332 - val_loss: 0.0405

Epoch 00718: val_loss did not improve from 0.02957
Epoch 719/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0484
2/2 [==============================] - 2s 1s/step - loss: 0.0427 - val_loss: 0.0390

Epoch 00719: val_loss did not improve from 0.02957
Epoch 720/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0451
2/2 [==============================] - 2s 1s/step - loss: 0.0434 - val_loss: 0.0344

Epoch 00720: val_loss did not improve from 0.02957
Epoch 721/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0375
2/2 [==============================] - 2s 1s/step - loss: 0.0390 - val_loss: 0.0369

Epoch 00721: val_loss did not improve from 0.02957
Epoch 722/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0424
2/2 [==============================] - 2s 1s/step - loss: 0.0357 - val_loss: 0.0401

Epoch 00722: val_loss did not improve from 0.02957
Epoch 723/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0412
2/2 [==============================] - 2s 1s/step - loss: 0.0408 - val_loss: 0.0353

Epoch 00723: val_loss did not improve from 0.02957
Epoch 724/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0450
2/2 [==============================] - 2s 1s/step - loss: 0.0448 - val_loss: 0.0365

Epoch 00724: val_loss did not improve from 0.02957
Epoch 725/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0425
2/2 [==============================] - 2s 1s/step - loss: 0.0375 - val_loss: 0.0365

Epoch 00725: val_loss did not improve from 0.02957
Epoch 726/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0368
2/2 [==============================] - 2s 1s/step - loss: 0.0405 - val_loss: 0.0383

Epoch 00726: val_loss did not improve from 0.02957
Epoch 727/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0345
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0397

Epoch 00727: val_loss did not improve from 0.02957
Epoch 728/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0348
2/2 [==============================] - 2s 1s/step - loss: 0.0405 - val_loss: 0.0423

Epoch 00728: val_loss did not improve from 0.02957
Epoch 729/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0412
2/2 [==============================] - 2s 1s/step - loss: 0.0388 - val_loss: 0.0379

Epoch 00729: val_loss did not improve from 0.02957
Epoch 730/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0392
2/2 [==============================] - 2s 1s/step - loss: 0.0382 - val_loss: 0.0433

Epoch 00730: val_loss did not improve from 0.02957
Epoch 731/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0392
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0413

Epoch 00731: val_loss did not improve from 0.02957
Epoch 732/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0442
2/2 [==============================] - 2s 1s/step - loss: 0.0471 - val_loss: 0.0376

Epoch 00732: val_loss did not improve from 0.02957
Epoch 733/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0437
2/2 [==============================] - 2s 1s/step - loss: 0.0440 - val_loss: 0.0436

Epoch 00733: val_loss did not improve from 0.02957
Epoch 734/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0416
2/2 [==============================] - 2s 1s/step - loss: 0.0434 - val_loss: 0.0406

Epoch 00734: val_loss did not improve from 0.02957
Epoch 735/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0445
2/2 [==============================] - 2s 1s/step - loss: 0.0445 - val_loss: 0.0438

Epoch 00735: val_loss did not improve from 0.02957
Epoch 736/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0423
2/2 [==============================] - 2s 1s/step - loss: 0.0400 - val_loss: 0.0395

Epoch 00736: val_loss did not improve from 0.02957
Epoch 737/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0447
2/2 [==============================] - 2s 1s/step - loss: 0.0391 - val_loss: 0.0449

Epoch 00737: val_loss did not improve from 0.02957
Epoch 738/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0427
2/2 [==============================] - 2s 1s/step - loss: 0.0450 - val_loss: 0.0356

Epoch 00738: val_loss did not improve from 0.02957
Epoch 739/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0375
2/2 [==============================] - 2s 1s/step - loss: 0.0355 - val_loss: 0.0416

Epoch 00739: val_loss did not improve from 0.02957
Epoch 740/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0388
2/2 [==============================] - 2s 1s/step - loss: 0.0404 - val_loss: 0.0421

Epoch 00740: val_loss did not improve from 0.02957
Epoch 741/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0448
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0430

Epoch 00741: val_loss did not improve from 0.02957
Epoch 742/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0413
2/2 [==============================] - 2s 1s/step - loss: 0.0436 - val_loss: 0.0417

Epoch 00742: val_loss did not improve from 0.02957
Epoch 743/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0380
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0426

Epoch 00743: val_loss did not improve from 0.02957
Epoch 744/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0375
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0335

Epoch 00744: val_loss did not improve from 0.02957
Epoch 745/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0423
2/2 [==============================] - 2s 1s/step - loss: 0.0429 - val_loss: 0.0448

Epoch 00745: val_loss did not improve from 0.02957
Epoch 746/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0424
2/2 [==============================] - 2s 1s/step - loss: 0.0405 - val_loss: 0.0359

Epoch 00746: val_loss did not improve from 0.02957
Epoch 747/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0323
2/2 [==============================] - 2s 1s/step - loss: 0.0383 - val_loss: 0.0347

Epoch 00747: val_loss did not improve from 0.02957
Epoch 748/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0425
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0378

Epoch 00748: val_loss did not improve from 0.02957
Epoch 749/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0345
2/2 [==============================] - 2s 1s/step - loss: 0.0368 - val_loss: 0.0395

Epoch 00749: val_loss did not improve from 0.02957
Epoch 750/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0378
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0413

Epoch 00750: val_loss did not improve from 0.02957
Epoch 751/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0324
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0431

Epoch 00751: val_loss did not improve from 0.02957
Epoch 752/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0434
2/2 [==============================] - 2s 1s/step - loss: 0.0405 - val_loss: 0.0426

Epoch 00752: val_loss did not improve from 0.02957
Epoch 753/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0358
2/2 [==============================] - 2s 1s/step - loss: 0.0350 - val_loss: 0.0451

Epoch 00753: val_loss did not improve from 0.02957
Epoch 754/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0346
2/2 [==============================] - 2s 1s/step - loss: 0.0382 - val_loss: 0.0382

Epoch 00754: val_loss did not improve from 0.02957
Epoch 755/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0376
2/2 [==============================] - 2s 1s/step - loss: 0.0388 - val_loss: 0.0398

Epoch 00755: val_loss did not improve from 0.02957
Epoch 756/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0336
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0391

Epoch 00756: val_loss did not improve from 0.02957
Epoch 757/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0323
2/2 [==============================] - 2s 1s/step - loss: 0.0380 - val_loss: 0.0480

Epoch 00757: val_loss did not improve from 0.02957
Epoch 758/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0376
2/2 [==============================] - 2s 1s/step - loss: 0.0404 - val_loss: 0.0471

Epoch 00758: val_loss did not improve from 0.02957
Epoch 759/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0375
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0392

Epoch 00759: val_loss did not improve from 0.02957
Epoch 760/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0330
2/2 [==============================] - 2s 1s/step - loss: 0.0369 - val_loss: 0.0378

Epoch 00760: val_loss did not improve from 0.02957
Epoch 761/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0327
2/2 [==============================] - 2s 1s/step - loss: 0.0348 - val_loss: 0.0413

Epoch 00761: val_loss did not improve from 0.02957
Epoch 762/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0355
2/2 [==============================] - 2s 1s/step - loss: 0.0359 - val_loss: 0.0433

Epoch 00762: val_loss did not improve from 0.02957
Epoch 763/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0463
2/2 [==============================] - 2s 1s/step - loss: 0.0449 - val_loss: 0.0403

Epoch 00763: val_loss did not improve from 0.02957
Epoch 764/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0396
2/2 [==============================] - 2s 1s/step - loss: 0.0351 - val_loss: 0.0412

Epoch 00764: val_loss did not improve from 0.02957
Epoch 765/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0424
2/2 [==============================] - 2s 1s/step - loss: 0.0437 - val_loss: 0.0370

Epoch 00765: val_loss did not improve from 0.02957
Epoch 766/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0398
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0472

Epoch 00766: val_loss did not improve from 0.02957
Epoch 767/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0421
2/2 [==============================] - 2s 1s/step - loss: 0.0463 - val_loss: 0.0434

Epoch 00767: val_loss did not improve from 0.02957
Epoch 768/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0360
2/2 [==============================] - 2s 1s/step - loss: 0.0364 - val_loss: 0.0419

Epoch 00768: val_loss did not improve from 0.02957
Epoch 769/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0410 - val_loss: 0.0417

Epoch 00769: val_loss did not improve from 0.02957
Epoch 770/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0406
2/2 [==============================] - 2s 1s/step - loss: 0.0441 - val_loss: 0.0400

Epoch 00770: val_loss did not improve from 0.02957
Epoch 771/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0408
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0384

Epoch 00771: val_loss did not improve from 0.02957
Epoch 772/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0411
2/2 [==============================] - 2s 1s/step - loss: 0.0427 - val_loss: 0.0387

Epoch 00772: val_loss did not improve from 0.02957
Epoch 773/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0465
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0370

Epoch 00773: val_loss did not improve from 0.02957
Epoch 774/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0436 - val_loss: 0.0420

Epoch 00774: val_loss did not improve from 0.02957
Epoch 775/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0383
2/2 [==============================] - 2s 1s/step - loss: 0.0414 - val_loss: 0.0334

Epoch 00775: val_loss did not improve from 0.02957
Epoch 776/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0373
2/2 [==============================] - 2s 1s/step - loss: 0.0395 - val_loss: 0.0428

Epoch 00776: val_loss did not improve from 0.02957
Epoch 777/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0416
2/2 [==============================] - 2s 1s/step - loss: 0.0380 - val_loss: 0.0434

Epoch 00777: val_loss did not improve from 0.02957
Epoch 778/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0371
2/2 [==============================] - 2s 1s/step - loss: 0.0363 - val_loss: 0.0398

Epoch 00778: val_loss did not improve from 0.02957
Epoch 779/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0453
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0405

Epoch 00779: val_loss did not improve from 0.02957
Epoch 780/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0411
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0421

Epoch 00780: val_loss did not improve from 0.02957
Epoch 781/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0342
2/2 [==============================] - 2s 1s/step - loss: 0.0356 - val_loss: 0.0469

Epoch 00781: val_loss did not improve from 0.02957
Epoch 782/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0448
2/2 [==============================] - 2s 1s/step - loss: 0.0433 - val_loss: 0.0437

Epoch 00782: val_loss did not improve from 0.02957
Epoch 783/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0428
2/2 [==============================] - 2s 1s/step - loss: 0.0426 - val_loss: 0.0404

Epoch 00783: val_loss did not improve from 0.02957
Epoch 784/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0350
2/2 [==============================] - 2s 1s/step - loss: 0.0367 - val_loss: 0.0422

Epoch 00784: val_loss did not improve from 0.02957
Epoch 785/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0447
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0358

Epoch 00785: val_loss did not improve from 0.02957
Epoch 786/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0430
2/2 [==============================] - 2s 1s/step - loss: 0.0430 - val_loss: 0.0383

Epoch 00786: val_loss did not improve from 0.02957
Epoch 787/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0366
2/2 [==============================] - 2s 1s/step - loss: 0.0369 - val_loss: 0.0409

Epoch 00787: val_loss did not improve from 0.02957
Epoch 788/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0467
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0324

Epoch 00788: val_loss did not improve from 0.02957
Epoch 789/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0452
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0469

Epoch 00789: val_loss did not improve from 0.02957
Epoch 790/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0447
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0385

Epoch 00790: val_loss did not improve from 0.02957
Epoch 791/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0325
2/2 [==============================] - 2s 1s/step - loss: 0.0333 - val_loss: 0.0432

Epoch 00791: val_loss did not improve from 0.02957
Epoch 792/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0325
2/2 [==============================] - 2s 1s/step - loss: 0.0337 - val_loss: 0.0413

Epoch 00792: val_loss did not improve from 0.02957
Epoch 793/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0372
2/2 [==============================] - 2s 1s/step - loss: 0.0361 - val_loss: 0.0422

Epoch 00793: val_loss did not improve from 0.02957
Epoch 794/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0346
2/2 [==============================] - 2s 1s/step - loss: 0.0366 - val_loss: 0.0409

Epoch 00794: val_loss did not improve from 0.02957
Epoch 795/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0445
2/2 [==============================] - 2s 1s/step - loss: 0.0451 - val_loss: 0.0430

Epoch 00795: val_loss did not improve from 0.02957
Epoch 796/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0441 - val_loss: 0.0426

Epoch 00796: val_loss did not improve from 0.02957
Epoch 797/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0411
2/2 [==============================] - 2s 1s/step - loss: 0.0426 - val_loss: 0.0348

Epoch 00797: val_loss did not improve from 0.02957
Epoch 798/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0409
2/2 [==============================] - 2s 1s/step - loss: 0.0409 - val_loss: 0.0409

Epoch 00798: val_loss did not improve from 0.02957
Epoch 799/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0393
2/2 [==============================] - 2s 1s/step - loss: 0.0417 - val_loss: 0.0362

Epoch 00799: val_loss did not improve from 0.02957
Epoch 800/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0395
2/2 [==============================] - 2s 1s/step - loss: 0.0384 - val_loss: 0.0457

Epoch 00800: val_loss did not improve from 0.02957
Epoch 801/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0424
2/2 [==============================] - 2s 1s/step - loss: 0.0422 - val_loss: 0.0418

Epoch 00801: val_loss did not improve from 0.02957
Epoch 802/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0382
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0435

Epoch 00802: val_loss did not improve from 0.02957
Epoch 803/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0351
2/2 [==============================] - 2s 1s/step - loss: 0.0393 - val_loss: 0.0314

Epoch 00803: val_loss did not improve from 0.02957
Epoch 804/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0449
2/2 [==============================] - 2s 1s/step - loss: 0.0457 - val_loss: 0.0380

Epoch 00804: val_loss did not improve from 0.02957
Epoch 805/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0445
2/2 [==============================] - 2s 1s/step - loss: 0.0426 - val_loss: 0.0399

Epoch 00805: val_loss did not improve from 0.02957
Epoch 806/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0401
2/2 [==============================] - 2s 1s/step - loss: 0.0417 - val_loss: 0.0415

Epoch 00806: val_loss did not improve from 0.02957
Epoch 807/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0496
2/2 [==============================] - 2s 1s/step - loss: 0.0429 - val_loss: 0.0368

Epoch 00807: val_loss did not improve from 0.02957
Epoch 808/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0282
2/2 [==============================] - 2s 1s/step - loss: 0.0361 - val_loss: 0.0372

Epoch 00808: val_loss did not improve from 0.02957
Epoch 809/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0444
2/2 [==============================] - 2s 1s/step - loss: 0.0450 - val_loss: 0.0406

Epoch 00809: val_loss did not improve from 0.02957
Epoch 810/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0433
2/2 [==============================] - 2s 1s/step - loss: 0.0452 - val_loss: 0.0408

Epoch 00810: val_loss did not improve from 0.02957
Epoch 811/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0454
2/2 [==============================] - 2s 1s/step - loss: 0.0427 - val_loss: 0.0337

Epoch 00811: val_loss did not improve from 0.02957
Epoch 812/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0406
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0374

Epoch 00812: val_loss did not improve from 0.02957
Epoch 813/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0427
2/2 [==============================] - 2s 1s/step - loss: 0.0446 - val_loss: 0.0423

Epoch 00813: val_loss did not improve from 0.02957
Epoch 814/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0397
2/2 [==============================] - 2s 1s/step - loss: 0.0347 - val_loss: 0.0450

Epoch 00814: val_loss did not improve from 0.02957
Epoch 815/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0371
2/2 [==============================] - 2s 1s/step - loss: 0.0394 - val_loss: 0.0411

Epoch 00815: val_loss did not improve from 0.02957
Epoch 816/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0407
2/2 [==============================] - 2s 1s/step - loss: 0.0375 - val_loss: 0.0447

Epoch 00816: val_loss did not improve from 0.02957
Epoch 817/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0397
2/2 [==============================] - 2s 1s/step - loss: 0.0420 - val_loss: 0.0386

Epoch 00817: val_loss did not improve from 0.02957
Epoch 818/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0467
2/2 [==============================] - 2s 1s/step - loss: 0.0452 - val_loss: 0.0434

Epoch 00818: val_loss did not improve from 0.02957
Epoch 819/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0368
2/2 [==============================] - 2s 1s/step - loss: 0.0410 - val_loss: 0.0378

Epoch 00819: val_loss did not improve from 0.02957
Epoch 820/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0428
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0395

Epoch 00820: val_loss did not improve from 0.02957
Epoch 821/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0390
2/2 [==============================] - 2s 1s/step - loss: 0.0355 - val_loss: 0.0387

Epoch 00821: val_loss did not improve from 0.02957
Epoch 822/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0385
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0408

Epoch 00822: val_loss did not improve from 0.02957
Epoch 823/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0427
2/2 [==============================] - 2s 1s/step - loss: 0.0389 - val_loss: 0.0441

Epoch 00823: val_loss did not improve from 0.02957
Epoch 824/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0411
2/2 [==============================] - 2s 1s/step - loss: 0.0410 - val_loss: 0.0370

Epoch 00824: val_loss did not improve from 0.02957
Epoch 825/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0384
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0410

Epoch 00825: val_loss did not improve from 0.02957
Epoch 826/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0389
2/2 [==============================] - 2s 1s/step - loss: 0.0387 - val_loss: 0.0438

Epoch 00826: val_loss did not improve from 0.02957
Epoch 827/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0331
2/2 [==============================] - 2s 1s/step - loss: 0.0390 - val_loss: 0.0410

Epoch 00827: val_loss did not improve from 0.02957
Epoch 828/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0430
2/2 [==============================] - 2s 1s/step - loss: 0.0423 - val_loss: 0.0418

Epoch 00828: val_loss did not improve from 0.02957
Epoch 829/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0392
2/2 [==============================] - 2s 1s/step - loss: 0.0342 - val_loss: 0.0366

Epoch 00829: val_loss did not improve from 0.02957
Epoch 830/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0461
2/2 [==============================] - 2s 1s/step - loss: 0.0448 - val_loss: 0.0417

Epoch 00830: val_loss did not improve from 0.02957
Epoch 831/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0412
2/2 [==============================] - 2s 1s/step - loss: 0.0405 - val_loss: 0.0450

Epoch 00831: val_loss did not improve from 0.02957
Epoch 832/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0362
2/2 [==============================] - 2s 1s/step - loss: 0.0344 - val_loss: 0.0444

Epoch 00832: val_loss did not improve from 0.02957
Epoch 833/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0402
2/2 [==============================] - 2s 1s/step - loss: 0.0429 - val_loss: 0.0386

Epoch 00833: val_loss did not improve from 0.02957
Epoch 834/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0393
2/2 [==============================] - 2s 1s/step - loss: 0.0369 - val_loss: 0.0458

Epoch 00834: val_loss did not improve from 0.02957
Epoch 835/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0458
2/2 [==============================] - 2s 1s/step - loss: 0.0383 - val_loss: 0.0429

Epoch 00835: val_loss did not improve from 0.02957
Epoch 836/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0445
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0360

Epoch 00836: val_loss did not improve from 0.02957
Epoch 837/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0378
2/2 [==============================] - 2s 1s/step - loss: 0.0406 - val_loss: 0.0460

Epoch 00837: val_loss did not improve from 0.02957
Epoch 838/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0417
2/2 [==============================] - 2s 1s/step - loss: 0.0456 - val_loss: 0.0401

Epoch 00838: val_loss did not improve from 0.02957
Epoch 839/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0391
2/2 [==============================] - 2s 1s/step - loss: 0.0424 - val_loss: 0.0354

Epoch 00839: val_loss did not improve from 0.02957
Epoch 840/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0417
2/2 [==============================] - 2s 1s/step - loss: 0.0395 - val_loss: 0.0424

Epoch 00840: val_loss did not improve from 0.02957
Epoch 841/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0428
2/2 [==============================] - 2s 1s/step - loss: 0.0458 - val_loss: 0.0388

Epoch 00841: val_loss did not improve from 0.02957
Epoch 842/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0440
2/2 [==============================] - 2s 1s/step - loss: 0.0465 - val_loss: 0.0434

Epoch 00842: val_loss did not improve from 0.02957
Epoch 843/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0384
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0471

Epoch 00843: val_loss did not improve from 0.02957
Epoch 844/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0490
2/2 [==============================] - 2s 1s/step - loss: 0.0468 - val_loss: 0.0462

Epoch 00844: val_loss did not improve from 0.02957
Epoch 845/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0468
2/2 [==============================] - 2s 1s/step - loss: 0.0437 - val_loss: 0.0390

Epoch 00845: val_loss did not improve from 0.02957
Epoch 846/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0397
2/2 [==============================] - 2s 1s/step - loss: 0.0364 - val_loss: 0.0431

Epoch 00846: val_loss did not improve from 0.02957
Epoch 847/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0468
2/2 [==============================] - 2s 1s/step - loss: 0.0414 - val_loss: 0.0397

Epoch 00847: val_loss did not improve from 0.02957
Epoch 848/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0416
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0390

Epoch 00848: val_loss did not improve from 0.02957
Epoch 849/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0413
2/2 [==============================] - 2s 1s/step - loss: 0.0389 - val_loss: 0.0375

Epoch 00849: val_loss did not improve from 0.02957
Epoch 850/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0344
2/2 [==============================] - 2s 1s/step - loss: 0.0392 - val_loss: 0.0430

Epoch 00850: val_loss did not improve from 0.02957
Epoch 851/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0379
2/2 [==============================] - 2s 1s/step - loss: 0.0382 - val_loss: 0.0336

Epoch 00851: val_loss did not improve from 0.02957
Epoch 852/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0440

Epoch 00852: val_loss did not improve from 0.02957
Epoch 853/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0482
2/2 [==============================] - 2s 1s/step - loss: 0.0406 - val_loss: 0.0411

Epoch 00853: val_loss did not improve from 0.02957
Epoch 854/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0362
2/2 [==============================] - 2s 1s/step - loss: 0.0347 - val_loss: 0.0398

Epoch 00854: val_loss did not improve from 0.02957
Epoch 855/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0438
2/2 [==============================] - 2s 1s/step - loss: 0.0399 - val_loss: 0.0349

Epoch 00855: val_loss did not improve from 0.02957
Epoch 856/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0385
2/2 [==============================] - 3s 1s/step - loss: 0.0369 - val_loss: 0.0418

Epoch 00856: val_loss did not improve from 0.02957
Epoch 857/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0462
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0408

Epoch 00857: val_loss did not improve from 0.02957
Epoch 858/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0369
2/2 [==============================] - 2s 1s/step - loss: 0.0342 - val_loss: 0.0356

Epoch 00858: val_loss did not improve from 0.02957
Epoch 859/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0382
2/2 [==============================] - 2s 1s/step - loss: 0.0408 - val_loss: 0.0417

Epoch 00859: val_loss did not improve from 0.02957
Epoch 860/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0418
2/2 [==============================] - 2s 1s/step - loss: 0.0409 - val_loss: 0.0412

Epoch 00860: val_loss did not improve from 0.02957
Epoch 861/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0461
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0410

Epoch 00861: val_loss did not improve from 0.02957
Epoch 862/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0361
2/2 [==============================] - 2s 1s/step - loss: 0.0409 - val_loss: 0.0407

Epoch 00862: val_loss did not improve from 0.02957
Epoch 863/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0444
2/2 [==============================] - 2s 1s/step - loss: 0.0412 - val_loss: 0.0396

Epoch 00863: val_loss did not improve from 0.02957
Epoch 864/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0429
2/2 [==============================] - 2s 1s/step - loss: 0.0439 - val_loss: 0.0416

Epoch 00864: val_loss did not improve from 0.02957
Epoch 865/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0347
2/2 [==============================] - 2s 1s/step - loss: 0.0378 - val_loss: 0.0430

Epoch 00865: val_loss did not improve from 0.02957
Epoch 866/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0356
2/2 [==============================] - 3s 1s/step - loss: 0.0379 - val_loss: 0.0455

Epoch 00866: val_loss did not improve from 0.02957
Epoch 867/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0341
2/2 [==============================] - 3s 1s/step - loss: 0.0345 - val_loss: 0.0396

Epoch 00867: val_loss did not improve from 0.02957
Epoch 868/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0409
2/2 [==============================] - 2s 1s/step - loss: 0.0411 - val_loss: 0.0402

Epoch 00868: val_loss did not improve from 0.02957
Epoch 869/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0393
2/2 [==============================] - 2s 1s/step - loss: 0.0410 - val_loss: 0.0400

Epoch 00869: val_loss did not improve from 0.02957
Epoch 870/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0384
2/2 [==============================] - 2s 1s/step - loss: 0.0387 - val_loss: 0.0408

Epoch 00870: val_loss did not improve from 0.02957
Epoch 871/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0391
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0367

Epoch 00871: val_loss did not improve from 0.02957
Epoch 872/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0389
2/2 [==============================] - 2s 1s/step - loss: 0.0391 - val_loss: 0.0361

Epoch 00872: val_loss did not improve from 0.02957
Epoch 873/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0451
2/2 [==============================] - 2s 1s/step - loss: 0.0365 - val_loss: 0.0396

Epoch 00873: val_loss did not improve from 0.02957
Epoch 874/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0435
2/2 [==============================] - 2s 1s/step - loss: 0.0461 - val_loss: 0.0363

Epoch 00874: val_loss did not improve from 0.02957
Epoch 875/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0267
2/2 [==============================] - 3s 1s/step - loss: 0.0366 - val_loss: 0.0431

Epoch 00875: val_loss did not improve from 0.02957
Epoch 876/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0339
2/2 [==============================] - 2s 1s/step - loss: 0.0349 - val_loss: 0.0349

Epoch 00876: val_loss did not improve from 0.02957
Epoch 877/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0405
2/2 [==============================] - 3s 1s/step - loss: 0.0440 - val_loss: 0.0397

Epoch 00877: val_loss did not improve from 0.02957
Epoch 878/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0328
2/2 [==============================] - 2s 1s/step - loss: 0.0323 - val_loss: 0.0314

Epoch 00878: val_loss did not improve from 0.02957
Epoch 879/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0403
2/2 [==============================] - 2s 1s/step - loss: 0.0392 - val_loss: 0.0419

Epoch 00879: val_loss did not improve from 0.02957
Epoch 880/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0395
2/2 [==============================] - 2s 1s/step - loss: 0.0383 - val_loss: 0.0419

Epoch 00880: val_loss did not improve from 0.02957
Epoch 881/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0382
2/2 [==============================] - 2s 1s/step - loss: 0.0374 - val_loss: 0.0393

Epoch 00881: val_loss did not improve from 0.02957
Epoch 882/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0384
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0451

Epoch 00882: val_loss did not improve from 0.02957
Epoch 883/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0358
2/2 [==============================] - 2s 1s/step - loss: 0.0390 - val_loss: 0.0380

Epoch 00883: val_loss did not improve from 0.02957
Epoch 884/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0408
2/2 [==============================] - 2s 1s/step - loss: 0.0423 - val_loss: 0.0411

Epoch 00884: val_loss did not improve from 0.02957
Epoch 885/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0401
2/2 [==============================] - 2s 1s/step - loss: 0.0395 - val_loss: 0.0416

Epoch 00885: val_loss did not improve from 0.02957
Epoch 886/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0355
2/2 [==============================] - 2s 1s/step - loss: 0.0385 - val_loss: 0.0364

Epoch 00886: val_loss did not improve from 0.02957
Epoch 887/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0418
2/2 [==============================] - 2s 1s/step - loss: 0.0428 - val_loss: 0.0345

Epoch 00887: val_loss did not improve from 0.02957
Epoch 888/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0410
2/2 [==============================] - 2s 1s/step - loss: 0.0407 - val_loss: 0.0417

Epoch 00888: val_loss did not improve from 0.02957
Epoch 889/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0361 - val_loss: 0.0379

Epoch 00889: val_loss did not improve from 0.02957
Epoch 890/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0438
2/2 [==============================] - 2s 1s/step - loss: 0.0346 - val_loss: 0.0425

Epoch 00890: val_loss did not improve from 0.02957
Epoch 891/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0475
2/2 [==============================] - 3s 1s/step - loss: 0.0453 - val_loss: 0.0449

Epoch 00891: val_loss did not improve from 0.02957
Epoch 892/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0370
2/2 [==============================] - 2s 1s/step - loss: 0.0424 - val_loss: 0.0456

Epoch 00892: val_loss did not improve from 0.02957
Epoch 893/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0401
2/2 [==============================] - 2s 1s/step - loss: 0.0347 - val_loss: 0.0396

Epoch 00893: val_loss did not improve from 0.02957
Epoch 894/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0427
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0407

Epoch 00894: val_loss did not improve from 0.02957
Epoch 895/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0240
2/2 [==============================] - 2s 1s/step - loss: 0.0287 - val_loss: 0.0360

Epoch 00895: val_loss did not improve from 0.02957
Epoch 896/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0429 - val_loss: 0.0425

Epoch 00896: val_loss did not improve from 0.02957
Epoch 897/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0436
2/2 [==============================] - 2s 1s/step - loss: 0.0350 - val_loss: 0.0400

Epoch 00897: val_loss did not improve from 0.02957
Epoch 898/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0465
2/2 [==============================] - 2s 1s/step - loss: 0.0376 - val_loss: 0.0431

Epoch 00898: val_loss did not improve from 0.02957
Epoch 899/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0326
2/2 [==============================] - 2s 1s/step - loss: 0.0376 - val_loss: 0.0423

Epoch 00899: val_loss did not improve from 0.02957
Epoch 900/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0389
2/2 [==============================] - 2s 1s/step - loss: 0.0381 - val_loss: 0.0348

Epoch 00900: val_loss did not improve from 0.02957
Epoch 901/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0392
2/2 [==============================] - 2s 1s/step - loss: 0.0448 - val_loss: 0.0290

Epoch 00901: val_loss improved from 0.02957 to 0.02901, saving model to weights.mse.data_06.raw.128_crop.latest.hdf5
Epoch 902/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0377
2/2 [==============================] - 2s 1s/step - loss: 0.0398 - val_loss: 0.0400

Epoch 00902: val_loss did not improve from 0.02901
Epoch 903/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0430
2/2 [==============================] - 2s 1s/step - loss: 0.0403 - val_loss: 0.0398

Epoch 00903: val_loss did not improve from 0.02901
Epoch 904/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0370
2/2 [==============================] - 2s 1s/step - loss: 0.0413 - val_loss: 0.0434

Epoch 00904: val_loss did not improve from 0.02901
Epoch 905/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0500
2/2 [==============================] - 2s 1s/step - loss: 0.0406 - val_loss: 0.0388

Epoch 00905: val_loss did not improve from 0.02901
Epoch 906/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0434
2/2 [==============================] - 3s 1s/step - loss: 0.0421 - val_loss: 0.0451

Epoch 00906: val_loss did not improve from 0.02901
Epoch 907/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0439
2/2 [==============================] - 2s 1s/step - loss: 0.0439 - val_loss: 0.0325

Epoch 00907: val_loss did not improve from 0.02901
Epoch 908/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0324
2/2 [==============================] - 2s 1s/step - loss: 0.0339 - val_loss: 0.0331

Epoch 00908: val_loss did not improve from 0.02901
Epoch 909/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0334
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0433

Epoch 00909: val_loss did not improve from 0.02901
Epoch 910/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0434
2/2 [==============================] - 2s 1s/step - loss: 0.0468 - val_loss: 0.0414

Epoch 00910: val_loss did not improve from 0.02901
Epoch 911/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0420
2/2 [==============================] - 2s 1s/step - loss: 0.0443 - val_loss: 0.0379

Epoch 00911: val_loss did not improve from 0.02901
Epoch 912/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0445
2/2 [==============================] - 2s 1s/step - loss: 0.0431 - val_loss: 0.0320

Epoch 00912: val_loss did not improve from 0.02901
Epoch 913/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0433
2/2 [==============================] - 2s 1s/step - loss: 0.0394 - val_loss: 0.0351

Epoch 00913: val_loss did not improve from 0.02901
Epoch 914/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0468
2/2 [==============================] - 2s 1s/step - loss: 0.0411 - val_loss: 0.0354

Epoch 00914: val_loss did not improve from 0.02901
Epoch 915/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0391
2/2 [==============================] - 3s 1s/step - loss: 0.0392 - val_loss: 0.0437

Epoch 00915: val_loss did not improve from 0.02901
Epoch 916/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0374
2/2 [==============================] - 2s 1s/step - loss: 0.0423 - val_loss: 0.0340

Epoch 00916: val_loss did not improve from 0.02901
Epoch 917/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0367
2/2 [==============================] - 2s 1s/step - loss: 0.0382 - val_loss: 0.0439

Epoch 00917: val_loss did not improve from 0.02901
Epoch 918/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0475
2/2 [==============================] - 2s 1s/step - loss: 0.0443 - val_loss: 0.0372

Epoch 00918: val_loss did not improve from 0.02901
Epoch 919/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0402
2/2 [==============================] - 2s 1s/step - loss: 0.0387 - val_loss: 0.0375

Epoch 00919: val_loss did not improve from 0.02901
Epoch 920/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0344
2/2 [==============================] - 2s 1s/step - loss: 0.0357 - val_loss: 0.0368

Epoch 00920: val_loss did not improve from 0.02901
Epoch 921/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0412
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0392

Epoch 00921: val_loss did not improve from 0.02901
Epoch 922/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0497
2/2 [==============================] - 2s 1s/step - loss: 0.0427 - val_loss: 0.0433

Epoch 00922: val_loss did not improve from 0.02901
Epoch 923/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0417
2/2 [==============================] - 2s 1s/step - loss: 0.0414 - val_loss: 0.0427

Epoch 00923: val_loss did not improve from 0.02901
Epoch 924/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0454
2/2 [==============================] - 2s 1s/step - loss: 0.0418 - val_loss: 0.0461

Epoch 00924: val_loss did not improve from 0.02901
Epoch 925/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0418
2/2 [==============================] - 2s 1s/step - loss: 0.0390 - val_loss: 0.0387

Epoch 00925: val_loss did not improve from 0.02901
Epoch 926/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0452
2/2 [==============================] - 2s 1s/step - loss: 0.0396 - val_loss: 0.0344

Epoch 00926: val_loss did not improve from 0.02901
Epoch 927/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0430
2/2 [==============================] - 2s 1s/step - loss: 0.0394 - val_loss: 0.0426

Epoch 00927: val_loss did not improve from 0.02901
Epoch 928/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0338
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0446

Epoch 00928: val_loss did not improve from 0.02901
Epoch 929/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0413
2/2 [==============================] - 3s 1s/step - loss: 0.0437 - val_loss: 0.0415

Epoch 00929: val_loss did not improve from 0.02901
Epoch 930/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0364
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0365

Epoch 00930: val_loss did not improve from 0.02901
Epoch 931/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0399
2/2 [==============================] - 2s 1s/step - loss: 0.0391 - val_loss: 0.0402

Epoch 00931: val_loss did not improve from 0.02901
Epoch 932/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0439
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0392

Epoch 00932: val_loss did not improve from 0.02901
Epoch 933/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0370
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0367

Epoch 00933: val_loss did not improve from 0.02901
Epoch 934/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0443
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0436

Epoch 00934: val_loss did not improve from 0.02901
Epoch 935/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0359
2/2 [==============================] - 2s 1s/step - loss: 0.0383 - val_loss: 0.0410

Epoch 00935: val_loss did not improve from 0.02901
Epoch 936/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0375
2/2 [==============================] - 2s 1s/step - loss: 0.0356 - val_loss: 0.0419

Epoch 00936: val_loss did not improve from 0.02901
Epoch 937/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0480
2/2 [==============================] - 3s 1s/step - loss: 0.0447 - val_loss: 0.0362

Epoch 00937: val_loss did not improve from 0.02901
Epoch 938/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0425
2/2 [==============================] - 3s 1s/step - loss: 0.0454 - val_loss: 0.0375

Epoch 00938: val_loss did not improve from 0.02901
Epoch 939/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0414
2/2 [==============================] - 3s 1s/step - loss: 0.0402 - val_loss: 0.0417

Epoch 00939: val_loss did not improve from 0.02901
Epoch 940/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0406
2/2 [==============================] - 2s 1s/step - loss: 0.0429 - val_loss: 0.0349

Epoch 00940: val_loss did not improve from 0.02901
Epoch 941/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0395
2/2 [==============================] - 2s 1s/step - loss: 0.0407 - val_loss: 0.0403

Epoch 00941: val_loss did not improve from 0.02901
Epoch 942/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0401
2/2 [==============================] - 2s 1s/step - loss: 0.0373 - val_loss: 0.0411

Epoch 00942: val_loss did not improve from 0.02901
Epoch 943/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0411
2/2 [==============================] - 2s 1s/step - loss: 0.0358 - val_loss: 0.0351

Epoch 00943: val_loss did not improve from 0.02901
Epoch 944/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0423
2/2 [==============================] - 2s 1s/step - loss: 0.0387 - val_loss: 0.0352

Epoch 00944: val_loss did not improve from 0.02901
Epoch 945/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0431
2/2 [==============================] - 2s 1s/step - loss: 0.0377 - val_loss: 0.0380

Epoch 00945: val_loss did not improve from 0.02901
Epoch 946/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0345
2/2 [==============================] - 2s 1s/step - loss: 0.0382 - val_loss: 0.0378

Epoch 00946: val_loss did not improve from 0.02901
Epoch 947/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0405
2/2 [==============================] - 3s 1s/step - loss: 0.0372 - val_loss: 0.0380

Epoch 00947: val_loss did not improve from 0.02901
Epoch 948/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0413
2/2 [==============================] - 3s 1s/step - loss: 0.0368 - val_loss: 0.0404

Epoch 00948: val_loss did not improve from 0.02901
Epoch 949/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0420
2/2 [==============================] - 3s 1s/step - loss: 0.0393 - val_loss: 0.0410

Epoch 00949: val_loss did not improve from 0.02901
Epoch 950/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0309
2/2 [==============================] - 2s 1s/step - loss: 0.0333 - val_loss: 0.0332

Epoch 00950: val_loss did not improve from 0.02901
Epoch 951/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0432
2/2 [==============================] - 2s 1s/step - loss: 0.0394 - val_loss: 0.0431

Epoch 00951: val_loss did not improve from 0.02901
Epoch 952/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0380
2/2 [==============================] - 2s 1s/step - loss: 0.0395 - val_loss: 0.0380

Epoch 00952: val_loss did not improve from 0.02901
Epoch 953/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0328
2/2 [==============================] - 2s 1s/step - loss: 0.0389 - val_loss: 0.0359

Epoch 00953: val_loss did not improve from 0.02901
Epoch 954/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0355
2/2 [==============================] - 2s 1s/step - loss: 0.0385 - val_loss: 0.0366

Epoch 00954: val_loss did not improve from 0.02901
Epoch 955/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0440
2/2 [==============================] - 2s 1s/step - loss: 0.0402 - val_loss: 0.0410

Epoch 00955: val_loss did not improve from 0.02901
Epoch 956/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0372
2/2 [==============================] - 2s 1s/step - loss: 0.0423 - val_loss: 0.0421

Epoch 00956: val_loss did not improve from 0.02901
Epoch 957/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0353
2/2 [==============================] - 2s 1s/step - loss: 0.0400 - val_loss: 0.0383

Epoch 00957: val_loss did not improve from 0.02901
Epoch 958/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0255
2/2 [==============================] - 2s 1s/step - loss: 0.0343 - val_loss: 0.0424

Epoch 00958: val_loss did not improve from 0.02901
Epoch 959/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0435
2/2 [==============================] - 3s 1s/step - loss: 0.0439 - val_loss: 0.0411

Epoch 00959: val_loss did not improve from 0.02901
Epoch 960/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0449
2/2 [==============================] - 2s 1s/step - loss: 0.0438 - val_loss: 0.0423

Epoch 00960: val_loss did not improve from 0.02901
Epoch 961/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0429
2/2 [==============================] - 3s 1s/step - loss: 0.0348 - val_loss: 0.0364

Epoch 00961: val_loss did not improve from 0.02901
Epoch 962/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0406
2/2 [==============================] - 2s 1s/step - loss: 0.0411 - val_loss: 0.0418

Epoch 00962: val_loss did not improve from 0.02901
Epoch 963/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0358
2/2 [==============================] - 3s 1s/step - loss: 0.0371 - val_loss: 0.0455

Epoch 00963: val_loss did not improve from 0.02901
Epoch 964/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0424
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0432

Epoch 00964: val_loss did not improve from 0.02901
Epoch 965/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0347
2/2 [==============================] - 2s 1s/step - loss: 0.0335 - val_loss: 0.0443

Epoch 00965: val_loss did not improve from 0.02901
Epoch 966/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0429
2/2 [==============================] - 2s 1s/step - loss: 0.0438 - val_loss: 0.0412

Epoch 00966: val_loss did not improve from 0.02901
Epoch 967/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0324
2/2 [==============================] - 3s 1s/step - loss: 0.0345 - val_loss: 0.0341

Epoch 00967: val_loss did not improve from 0.02901
Epoch 968/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0419
2/2 [==============================] - 2s 1s/step - loss: 0.0420 - val_loss: 0.0399

Epoch 00968: val_loss did not improve from 0.02901
Epoch 969/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0328
2/2 [==============================] - 2s 1s/step - loss: 0.0349 - val_loss: 0.0413

Epoch 00969: val_loss did not improve from 0.02901
Epoch 970/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0342
2/2 [==============================] - 2s 1s/step - loss: 0.0397 - val_loss: 0.0432

Epoch 00970: val_loss did not improve from 0.02901
Epoch 971/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0421
2/2 [==============================] - 3s 1s/step - loss: 0.0428 - val_loss: 0.0435

Epoch 00971: val_loss did not improve from 0.02901
Epoch 972/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0451
2/2 [==============================] - 2s 1s/step - loss: 0.0425 - val_loss: 0.0408

Epoch 00972: val_loss did not improve from 0.02901
Epoch 973/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0413
2/2 [==============================] - 3s 1s/step - loss: 0.0393 - val_loss: 0.0432

Epoch 00973: val_loss did not improve from 0.02901
Epoch 974/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0466
2/2 [==============================] - 2s 1s/step - loss: 0.0421 - val_loss: 0.0412

Epoch 00974: val_loss did not improve from 0.02901
Epoch 975/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0345
2/2 [==============================] - 2s 1s/step - loss: 0.0404 - val_loss: 0.0422

Epoch 00975: val_loss did not improve from 0.02901
Epoch 976/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0401
2/2 [==============================] - 3s 1s/step - loss: 0.0426 - val_loss: 0.0346

Epoch 00976: val_loss did not improve from 0.02901
Epoch 977/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0369
2/2 [==============================] - 2s 1s/step - loss: 0.0370 - val_loss: 0.0479

Epoch 00977: val_loss did not improve from 0.02901
Epoch 978/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0389
2/2 [==============================] - 3s 1s/step - loss: 0.0411 - val_loss: 0.0327

Epoch 00978: val_loss did not improve from 0.02901
Epoch 979/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0396
2/2 [==============================] - 2s 1s/step - loss: 0.0394 - val_loss: 0.0397

Epoch 00979: val_loss did not improve from 0.02901
Epoch 980/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0268
2/2 [==============================] - 2s 1s/step - loss: 0.0306 - val_loss: 0.0418

Epoch 00980: val_loss did not improve from 0.02901
Epoch 981/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0360
2/2 [==============================] - 2s 1s/step - loss: 0.0371 - val_loss: 0.0435

Epoch 00981: val_loss did not improve from 0.02901
Epoch 982/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0390
2/2 [==============================] - 2s 1s/step - loss: 0.0415 - val_loss: 0.0377

Epoch 00982: val_loss did not improve from 0.02901
Epoch 983/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0437
2/2 [==============================] - 3s 1s/step - loss: 0.0398 - val_loss: 0.0340

Epoch 00983: val_loss did not improve from 0.02901
Epoch 984/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0438
2/2 [==============================] - 2s 1s/step - loss: 0.0430 - val_loss: 0.0443

Epoch 00984: val_loss did not improve from 0.02901
Epoch 985/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0335
2/2 [==============================] - 2s 1s/step - loss: 0.0400 - val_loss: 0.0389

Epoch 00985: val_loss did not improve from 0.02901
Epoch 986/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0469
2/2 [==============================] - 2s 1s/step - loss: 0.0444 - val_loss: 0.0453

Epoch 00986: val_loss did not improve from 0.02901
Epoch 987/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0243
2/2 [==============================] - 2s 1s/step - loss: 0.0276 - val_loss: 0.0408

Epoch 00987: val_loss did not improve from 0.02901
Epoch 988/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0320
2/2 [==============================] - 2s 1s/step - loss: 0.0367 - val_loss: 0.0446

Epoch 00988: val_loss did not improve from 0.02901
Epoch 989/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0425
2/2 [==============================] - 2s 1s/step - loss: 0.0376 - val_loss: 0.0444

Epoch 00989: val_loss did not improve from 0.02901
Epoch 990/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0346
2/2 [==============================] - 3s 1s/step - loss: 0.0369 - val_loss: 0.0359

Epoch 00990: val_loss did not improve from 0.02901
Epoch 991/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0408
2/2 [==============================] - 2s 1s/step - loss: 0.0416 - val_loss: 0.0392

Epoch 00991: val_loss did not improve from 0.02901
Epoch 992/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0455
2/2 [==============================] - 2s 1s/step - loss: 0.0432 - val_loss: 0.0381

Epoch 00992: val_loss did not improve from 0.02901
Epoch 993/1000

1/2 [==============>...............] - ETA: 1s - loss: 0.0433
2/2 [==============================] - 3s 1s/step - loss: 0.0409 - val_loss: 0.0398

Epoch 00993: val_loss did not improve from 0.02901
Epoch 994/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0441
2/2 [==============================] - 2s 1s/step - loss: 0.0433 - val_loss: 0.0349

Epoch 00994: val_loss did not improve from 0.02901
Epoch 995/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0414
2/2 [==============================] - 2s 1s/step - loss: 0.0391 - val_loss: 0.0394

Epoch 00995: val_loss did not improve from 0.02901
Epoch 996/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0412
2/2 [==============================] - 2s 1s/step - loss: 0.0406 - val_loss: 0.0352

Epoch 00996: val_loss did not improve from 0.02901
Epoch 997/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0466
2/2 [==============================] - 2s 1s/step - loss: 0.0389 - val_loss: 0.0331

Epoch 00997: val_loss did not improve from 0.02901
Epoch 998/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0394
2/2 [==============================] - 2s 1s/step - loss: 0.0413 - val_loss: 0.0332

Epoch 00998: val_loss did not improve from 0.02901
Epoch 999/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0361
2/2 [==============================] - 2s 1s/step - loss: 0.0379 - val_loss: 0.0407

Epoch 00999: val_loss did not improve from 0.02901
Epoch 1000/1000

1/2 [==============>...............] - ETA: 0s - loss: 0.0427
2/2 [==============================] - 2s 1s/step - loss: 0.0389 - val_loss: 0.0343

Epoch 01000: val_loss did not improve from 0.02901
